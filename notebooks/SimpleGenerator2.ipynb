{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dbf34a7-a58e-49a2-aa4b-8bca5f58c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "import statistics\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36cedf6f-e5e8-4d3f-8d91-7e3d843b11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dir_if_not_exists(directory):\n",
    "\tif not os.path.exists(directory):\n",
    "\t\tlogging.info(\"Creating new directory: {}\".format(directory))\n",
    "\t\tos.makedirs(directory)\n",
    "\n",
    "def print_list(l, K=None):\n",
    "\tfor i, e in enumerate(l):\n",
    "\t\tif i == K:\n",
    "\t\t\tbreak\n",
    "\t\tprint(e)\n",
    "\tprint()\n",
    "\n",
    "def remove_multiple_spaces(string):\n",
    "\treturn re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "def save_in_pickle(save_object, save_file):\n",
    "\twith open(save_file, \"wb\") as pickle_out:\n",
    "\t\tpickle.dump(save_object, pickle_out)\n",
    "\n",
    "def load_from_pickle(pickle_file):\n",
    "\twith open(pickle_file, \"rb\") as pickle_in:\n",
    "\t\treturn pickle.load(pickle_in)\n",
    "\n",
    "def save_in_txt(list_of_strings, save_file):\n",
    "\twith open(save_file, \"w\") as writer:\n",
    "\t\tfor line in list_of_strings:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\twriter.write(f\"{line}\\n\")\n",
    "\n",
    "def load_from_txt(txt_file):\n",
    "\twith open(txt_file, \"r\") as reader:\n",
    "\t\tall_lines = list()\n",
    "\t\tfor line in reader:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\tall_lines.append(line)\n",
    "\t\treturn all_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ed704e-8f0c-4750-8c2c-a085911ea7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e20b3775-ea62-4292-97b9-c7f2e3d015a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n",
      "                                    author  \\\n",
      "0                      WILLIAM SHAKESPEARE   \n",
      "1  DUCHESS OF NEWCASTLE MARGARET CAVENDISH   \n",
      "2                           THOMAS BASTARD   \n",
      "3                           EDMUND SPENSER   \n",
      "4                        RICHARD BARNFIELD   \n",
      "\n",
      "                                             content  \\\n",
      "0  Let the bird of loudest lay\\nOn the sole Arabi...   \n",
      "1  Sir Charles into my chamber coming in,\\nWhen I...   \n",
      "2  Our vice runs beyond all that old men saw,\\nAn...   \n",
      "3  Lo I the man, whose Muse whilome did maske,\\nA...   \n",
      "4  Long have I longd to see my love againe,\\nStil...   \n",
      "\n",
      "                                 poem name          age                  type  \n",
      "0               The Phoenix and the Turtle  Renaissance  Mythology & Folklore  \n",
      "1                 An Epilogue to the Above  Renaissance  Mythology & Folklore  \n",
      "2                       Book 7, Epigram 42  Renaissance  Mythology & Folklore  \n",
      "3  from The Faerie Queene: Book I, Canto I  Renaissance  Mythology & Folklore  \n",
      "4                                Sonnet 16  Renaissance  Mythology & Folklore  \n"
     ]
    }
   ],
   "source": [
    "data_file = '../data/with_epoque.csv'\n",
    "data = pd.read_csv(data_file)\n",
    "print(len(data))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8073de9-4b6d-4117-8704-60a2266e4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_training(df, char_max_line = 20):\n",
    "    inputs = []\n",
    "    context = []\n",
    "    targets = []\n",
    "    previous = []\n",
    "    for i,rows in df.iterrows():\n",
    "        splitted = rows['content'].split('\\n')\n",
    "        if len(splitted) > 4:\n",
    "            for i,line in enumerate(splitted): \n",
    "                if len(line.strip()) > 0 and len(line.split(' ')) <= char_max_line:\n",
    "                    if i==0:\n",
    "                        previous.append(' ')\n",
    "                    else:\n",
    "                        previous.append(splitted[i-1])\n",
    "                    inputs.append(line)\n",
    "                    targets.append(line)\n",
    "                    context.append(' '.join([str(rows['author'])]))\n",
    "        \n",
    "    return pd.DataFrame(list(zip(inputs, context, targets, previous)),columns =['text', 'context','target', 'previous'])\n",
    "\n",
    "\n",
    "class PoemDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a8aecb5-c164-4b77-8849-4c686c2abb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    text              context  \\\n",
      "0            Let the bird of loudest lay  WILLIAM SHAKESPEARE   \n",
      "1               On the sole Arabian tree  WILLIAM SHAKESPEARE   \n",
      "2             Herald sad and trumpet be,  WILLIAM SHAKESPEARE   \n",
      "3      To whose sound chaste wings obey.  WILLIAM SHAKESPEARE   \n",
      "4          But thou shrieking harbinger,  WILLIAM SHAKESPEARE   \n",
      "...                                  ...                  ...   \n",
      "13480              And the lisp of reeds    RICHARD ALDINGTON   \n",
      "13481      And the sun upon thy breasts,    RICHARD ALDINGTON   \n",
      "13482           And thou hearest me not,    RICHARD ALDINGTON   \n",
      "13483                     Potuia, potuia    RICHARD ALDINGTON   \n",
      "13484               Thou hearest me not.    RICHARD ALDINGTON   \n",
      "\n",
      "                                  target                       previous  \n",
      "0            Let the bird of loudest lay                                 \n",
      "1               On the sole Arabian tree    Let the bird of loudest lay  \n",
      "2             Herald sad and trumpet be,       On the sole Arabian tree  \n",
      "3      To whose sound chaste wings obey.     Herald sad and trumpet be,  \n",
      "4          But thou shrieking harbinger,                                 \n",
      "...                                  ...                            ...  \n",
      "13480              And the lisp of reeds  I have told thee of the hills  \n",
      "13481      And the sun upon thy breasts,          And the lisp of reeds  \n",
      "13482           And thou hearest me not,                                 \n",
      "13483                     Potuia, potuia       And thou hearest me not,  \n",
      "13484               Thou hearest me not.                 Potuia, potuia  \n",
      "\n",
      "[13485 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = make_data_training(data, char_max_line = 30)\n",
    "\n",
    "all_poems = df['text'].tolist()\n",
    "context = df['context'].tolist()\n",
    "previous = df['previous'].tolist()\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62e57386-ac09-497e-9040-b22699b38e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the vocabulary = 11264\n"
     ]
    }
   ],
   "source": [
    "pad_word = \"<pad>\"\n",
    "bos_word = \"<bos>\"\n",
    "eos_word = \"<eos>\"\n",
    "unk_word = \"<unk>\"\n",
    "sep_word = \"sep\"\n",
    "\n",
    "pad_id = 0\n",
    "bos_id = 1\n",
    "eos_id = 2\n",
    "unk_id = 3\n",
    "sep_id = 4\n",
    "    \n",
    "def normalize_sentence(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word_to_id = {pad_word: pad_id, bos_word: bos_id, eos_word:eos_id, unk_word: unk_id, sep_word: sep_id}\n",
    "        self.word_count = {}\n",
    "        self.id_to_word = {pad_id: pad_word, bos_id: bos_word, eos_id: eos_word, unk_id: unk_word, sep_id: sep_word}\n",
    "        self.num_words = 5\n",
    "    \n",
    "    def get_ids_from_sentence(self, sentence):\n",
    "        sentence = normalize_sentence(sentence)\n",
    "        sent_ids = [bos_id] + [self.word_to_id[word.lower()] if word.lower() in self.word_to_id \\\n",
    "                               else unk_id for word in sentence.split()] + \\\n",
    "                               [eos_id]\n",
    "        return sent_ids\n",
    "    \n",
    "    def tokenized_sentence(self, sentence):\n",
    "        sent_ids = self.get_ids_from_sentence(sentence)\n",
    "        return [self.id_to_word[word_id] for word_id in sent_ids]\n",
    "\n",
    "    def decode_sentence_from_ids(self, sent_ids):\n",
    "        words = list()\n",
    "        for i, word_id in enumerate(sent_ids):\n",
    "            if word_id in [bos_id, eos_id, pad_id]:\n",
    "                continue\n",
    "            else:\n",
    "                words.append(self.id_to_word[word_id])\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def add_words_from_sentence(self, sentence):\n",
    "        sentence = normalize_sentence(sentence)\n",
    "        for word in sentence.split():\n",
    "            if word not in self.word_to_id:\n",
    "                self.word_to_id[word] = self.num_words\n",
    "                self.id_to_word[self.num_words] = word\n",
    "                self.word_count[word] = 1\n",
    "                self.num_words += 1\n",
    "            else:\n",
    "                self.word_count[word] += 1\n",
    "\n",
    "vocab = Vocabulary()\n",
    "for src in df['text']:\n",
    "    vocab.add_words_from_sentence(src.lower())\n",
    "    \n",
    "for cxt in df['context']:\n",
    "    vocab.add_words_from_sentence(cxt.lower())\n",
    "\n",
    "print(f\"Total words in the vocabulary = {vocab.num_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cbcf941-49e1-475b-83fe-bf5b3445244e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1295/1910606831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfIdfVectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtfIdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfIdfVectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_poems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfIdfVectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Let the bird of loudest lay\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[1;32m   1845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m   1134\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfIdfVectorizer=TfidfVectorizer()\n",
    "tfIdf = tfIdfVectorizer.fit_transform(all_poems)\n",
    "\n",
    "X = tfIdfVectorizer.transform([\"Let the bird of loudest lay\"])\n",
    "names = np.array(tfIdfVectorizer.get_feature_names())\n",
    "ind = np.array(X.indices[X.data.sort()][0][-3:][::-1])\n",
    "res = names[ind]\n",
    "\n",
    "print(' '.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca140986-dc0a-446c-8ac4-c40832df65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poem_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, poems, context, previous, vocab, device):\n",
    "\n",
    "        l = []\n",
    "        \n",
    "        for i in range(len(poems)):\n",
    "            X = tfIdfVectorizer.transform([poems[i]])\n",
    "            ind = np.array(X.indices[X.data.sort()][0][-3:][::-1])\n",
    "            key_words = names[ind]\n",
    "            l.append( (context[i] + \" sep \" + ' '.join(key_words), poems[i] ))\n",
    "        \n",
    "        self.poems = l.copy()\n",
    "        self.vocab = vocab\n",
    "        self.device = device\n",
    "\n",
    "        def encode(src, tgt):\n",
    "            src_ids = self.vocab.get_ids_from_sentence(src)\n",
    "            tgt_ids = self.vocab.get_ids_from_sentence(tgt)\n",
    "            return (src_ids, tgt_ids)\n",
    "\n",
    "        # We will pre-tokenize the conversations and save in id lists for later use\n",
    "        self.tokenized_poems = [encode(src, tgt) for src, tgt in self.poems]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.poems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return {\"conv_ids\":self.tokenized_poems[idx], \"conv\":self.poems[idx]}\n",
    "\n",
    "def collate_fn(data):\n",
    "    src_ids = [torch.LongTensor(e[\"conv_ids\"][0]) for e in data]\n",
    "    tgt_ids = [torch.LongTensor(e[\"conv_ids\"][1]) for e in data]\n",
    "    src_str = [e[\"conv\"][0] for e in data]\n",
    "    tgt_str = [e[\"conv\"][1] for e in data]\n",
    "    data = list(zip(src_ids, tgt_ids, src_str, tgt_str))\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    src_ids, tgt_ids, src_str, tgt_str = zip(*data)\n",
    "\n",
    "    src_seqs = nn.utils.rnn.pad_sequence(src_ids, padding_value = pad_id,\n",
    "                                         batch_first = False)\n",
    "    tgt_seqs = nn.utils.rnn.pad_sequence(tgt_ids, padding_value = pad_id, \n",
    "                                         batch_first = False)\n",
    "    \n",
    "    src_padded_length = len(src_seqs[0])\n",
    "    tgt_padded_length = len(tgt_seqs[0])\n",
    "    return {\"conv_ids\":(src_ids, tgt_ids), \"conv\":(src_str, tgt_str), \"conv_tensors\":(src_seqs.to(device), tgt_seqs.to(device))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a2568c4-1691-438d-8032-4efce1c000b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Poem_dataset(all_poems, context, previous, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84b29501-e2a3-4f45-a3e9-8287376d0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, tgt in dataset.poems[0:5]:\n",
    "    sentence = src\n",
    "    word_tokens = vocab.tokenized_sentence(sentence)\n",
    "    word_ids = vocab.get_ids_from_sentence(sentence)\n",
    "    print(sentence)\n",
    "    print(tgt)\n",
    "    print(word_tokens)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd5c86bc-fb94-4706-a149-41eab9370f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_GloVe(filename):\n",
    "  embeddings = {}\n",
    "  for line in open(filename).readlines():\n",
    "    fields = line.strip().split(\" \")\n",
    "    word = fields[0]\n",
    "    embeddings[word] = [float(x) for x in fields[1:]]\n",
    "  return embeddings\n",
    "\n",
    "GloVe = read_GloVe(\"../data/glove.840B.300d.conll_filtered.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab4b33b3-dd1b-4d0a-8812-38495c9bad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Erato(nn.Module):\n",
    "    def __init__(self, vocab, emb_dim = 300, hidden_dim = 300, num_layers = 2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.num_words = num_words = vocab.num_words\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "   \n",
    "        self.encode_emb = nn.Embedding(self.num_words,self.emb_dim)\n",
    "        \n",
    "        self.init_glove(GloVe, vocab)\n",
    "        \n",
    "        self.encode_gru = nn.GRU(self.emb_dim, self.hidden_dim,\n",
    "                          num_layers=self.num_layers, dropout=dropout,\n",
    "                          bidirectional=True,batch_first=False)\n",
    "        self.encode_l_hidden = nn.Linear(2*self.num_layers,self.num_layers)\n",
    "        self.encode_l_output = nn.Linear(2*self.hidden_dim,self.hidden_dim)\n",
    "\n",
    "        self.dropout_enc = nn.Dropout(dropout)\n",
    "\n",
    "        self.decode_emb = self.encode_emb\n",
    "        \n",
    "        self.decode_gru = nn.GRU(self.emb_dim, self.hidden_dim,\n",
    "                          num_layers=self.num_layers, dropout=dropout,\n",
    "                          bidirectional=False,batch_first=False)\n",
    "        self.d_l = nn.Linear(self.hidden_dim,self.num_words)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=2)\n",
    "        self.loss = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "        self.dropout_dec = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax_att = nn.Softmax(dim=0)\n",
    "        self.attention_matrix = nn.Linear(self.hidden_dim,self.hidden_dim)\n",
    "        self.attention_decode_cat = nn.Linear(2*self.hidden_dim,self.num_words)\n",
    "    \n",
    "    def init_glove(self, GloVe, vocab):\n",
    "        weights_emb = self.encode_emb.weight.data.clone()\n",
    "        \n",
    "        for i, word in enumerate(vocab.word_to_id):\n",
    "            if word in GloVe:\n",
    "                weights_emb[vocab.word_to_id[word],:] = torch.tensor(GloVe[word])\n",
    "          \n",
    "        self.encode_emb = nn.Embedding.from_pretrained(weights_emb.clone(),freeze = False)\n",
    "    \n",
    "    def encode(self, source):\n",
    "        source_lengths = torch.sum(source != pad_id, axis=0).cpu()\n",
    "\n",
    "        emb = self.dropout_enc(self.encode_emb(source))\n",
    "        emb = nn.utils.rnn.pack_padded_sequence(emb, source_lengths,\n",
    "                                                enforce_sorted = False)\n",
    "        encoder_output, encoder_hidden = self.encode_gru(emb)\n",
    "        encoder_output,_ = nn.utils.rnn.pad_packed_sequence(encoder_output,\n",
    "                                                   padding_value=pad_id)\n",
    "  \n",
    "        encoder_output = self.encode_l_output(encoder_output)\n",
    "        \n",
    "        encoder_hidden = self.encode_l_hidden(encoder_hidden.permute(2,1,0))\n",
    "        encoder_hidden = encoder_hidden.permute(2,1,0).contiguous()\n",
    "        # Compute the encoder mask\n",
    "        encoder_mask = (source == pad_id)\n",
    "\n",
    "        return encoder_output, encoder_mask.type(torch.bool), encoder_hidden\n",
    "\n",
    "    def decode(self, decoder_input, last_hidden, encoder_output, encoder_mask):\n",
    "\n",
    "        emb = self.dropout_dec(self.decode_emb(decoder_input))\n",
    "        decoder_output, decoder_hidden = self.decode_gru(emb,last_hidden)\n",
    "        b = decoder_output.squeeze(0)\n",
    "\n",
    "        # I use the General method (Luong2015) for attention\n",
    "        encoder_output = encoder_output.masked_fill(encoder_mask.unsqueeze(2),0)\n",
    "        att = torch.matmul(self.attention_matrix(decoder_output.permute(1,0,2)),\n",
    "                           encoder_output.permute(1,2,0))\n",
    "        att = att.squeeze(1).permute(1,0)\n",
    "        \n",
    "        att = att.masked_fill(encoder_mask, float(\"-inf\"))\n",
    "        att = self.softmax_att(att)\n",
    "        c = att.unsqueeze(2) * encoder_output\n",
    "        c = torch.sum(c,0)\n",
    "        logits = self.attention_decode_cat(torch.cat((b,c),1))\n",
    "        return (logits, decoder_hidden, att)\n",
    "\n",
    "    def compute_loss(self, source, target):\n",
    "\n",
    "        max_source_sequence_length = target.shape[0]\n",
    "        local_batch_size = target.shape[1]\n",
    "        encoder_output, encoder_mask, h = self.encode(source)\n",
    "        input_decode = target[0,:].unsqueeze(0)\n",
    "        loss = 0\n",
    "        for t in range(1,max_source_sequence_length):\n",
    "            out,h,_ = self.decode(input_decode, h, encoder_output, encoder_mask)\n",
    "            input_decode = target[t,:].unsqueeze(0)\n",
    "            loss += self.loss(out, input_decode.squeeze())\n",
    "        return loss / (max_source_sequence_length-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c01483e-0a77-43d9-b785-90301515be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, num_epochs, model_file, learning_rate=0.0001):\n",
    "\n",
    "    decoder_learning_ratio = 5.0\n",
    "    encoder_parameter_names = ['encode_emb', 'encode_gru', 'l1', 'l2']\n",
    "                           \n",
    "    encoder_named_params = list(filter(lambda kv: any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
    "    decoder_named_params = list(filter(lambda kv: not any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
    "    encoder_params = [e[1] for e in encoder_named_params]\n",
    "    decoder_params = [e[1] for e in decoder_named_params]\n",
    "    optimizer = torch.optim.AdamW([{'params': encoder_params},\n",
    "                {'params': decoder_params, 'lr': learning_rate * decoder_learning_ratio}], lr=learning_rate)\n",
    "    \n",
    "    clip = 50.0\n",
    "    for epoch in tqdm.notebook.trange(num_epochs, desc=\"training\", unit=\"epoch\"):\n",
    "        with tqdm.notebook.tqdm(\n",
    "                data_loader,\n",
    "                desc=\"epoch {}\".format(epoch + 1),\n",
    "                unit=\"batch\",\n",
    "                total=len(data_loader)) as batch_iterator:\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for i, batch_data in enumerate(batch_iterator, start=1):\n",
    "                source, target = batch_data[\"conv_tensors\"]\n",
    "                optimizer.zero_grad()\n",
    "                loss = model.compute_loss(source, target)\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                _ = nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item())\n",
    "       \n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56066f16-c0f0-4c45-8ac2-53d0f918695e",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55260cf1-8ca4-4de1-af19-31d0b89de0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1295/3865624695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mErato_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErato\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Erato_model = Erato(vocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03bf5213-4d86-44f1-9629-d68009bf73e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1295/1512141998.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m data_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                shuffle=True, collate_fn=collate_fn)\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                     \u001b[0;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs7643-a4/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0m\u001b[1;32m    103\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                               shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d1763-fcb6-4ee4-8958-c24272551fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3250c3a-5cd5-45df-99ee-bfa97cdc34a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09894004ac9473ebf8c5139f413001c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad29e7a5b9eb4e789da6b9ce7c34b842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45147519f9474313a3784bf83630ab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f86b37aa1ec45e58f9a5ea90e0203ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8ce2932798409d9a69712afc1cf206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b68f43d7474829aa432010c6f15e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b968569a3e41d38f4bc7900c1cf8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220b9f1404d24be9b8d2538239bec0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1237f8cd5ea246aa8297bbab81c539a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                               shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "train(Erato_model, data_loader, num_epochs, \"baseline_model.pt\",learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "eb7d37ef-ac4f-4791-9ad5-3b350f514517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_greedy(model, sentence, max_length=100):\n",
    "    \"\"\"Make predictions for the given input using greedy inference.\n",
    "    \n",
    "    Args:\n",
    "        model: A sequence-to-sequence model.\n",
    "        sentence: A input string.\n",
    "        max_length: The maximum length at which to truncate outputs in order to\n",
    "            avoid non-terminating inference.\n",
    "    \n",
    "    Returns:\n",
    "        Model's predicted greedy response for the input, represented as string.\n",
    "    \"\"\"\n",
    "\n",
    "    # You should make only one call to model.encode() at the start of the function, \n",
    "    # and make only one call to model.decode() per inference step.\n",
    "    model.eval()    \n",
    "    src_id = torch.tensor(vocab.get_ids_from_sentence(sentence))[:,None].to(device)\n",
    "    encoder_output, encoder_mask, last_hidden = model.encode(src_id) \n",
    "    input = src_id[0,:]\n",
    "    out = [bos_id]\n",
    "    for t in range(max_length):\n",
    "        input = input[None,:]\n",
    "        out_decoder, last_hidden, _ = model.decode(input, last_hidden, encoder_output, encoder_mask)\n",
    "        input = out_decoder.argmax(dim=-1)\n",
    "        word = input.item()\n",
    "        out.append(word)\n",
    "        if word == eos_id:\n",
    "            break\n",
    "    \n",
    "    decoded = vocab.decode_sentence_from_ids(out)\n",
    "    return decoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "c8a35318-02d0-46b1-9be2-e57f82b556e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam(model, sentence, k=5, max_length=100, hidden = None):\n",
    "\n",
    "    alpha = 0.3\n",
    "    model.eval()\n",
    "    \n",
    "    sentence_ids = torch.tensor(vocab.get_ids_from_sentence(sentence)).cuda()\n",
    "    sentence_ids = sentence_ids.unsqueeze(1)\n",
    "    encoder_output, encoder_mask, h = model.encode(sentence_ids)\n",
    "\n",
    "    out_start = sentence_ids[0]\n",
    "    beam = [out_start for i in range(k)]\n",
    "    beam_scores = [1 for i in range(k)]\n",
    "    \n",
    "    if hidden:\n",
    "        h = hidden\n",
    "    hiddens = [h for i in range(k)]\n",
    "    \n",
    "    generations = []\n",
    "    generations_scores = []\n",
    "    curr_l = 0\n",
    "    eos_tensor = torch.Tensor([eos_id]).int().cuda()\n",
    "    while beam:\n",
    "        logits = torch.Tensor().cuda()\n",
    "        inds = torch.Tensor().int().cuda()\n",
    "        curr_k = len(beam)\n",
    "        if curr_l==max_length:\n",
    "            for i in range(curr_k):\n",
    "                  generations += [torch.cat((beam[i],eos_tensor),0)]\n",
    "                  generations_scores += [new_beam_scores[i]]\n",
    "            break\n",
    "        else:\n",
    "            for i in range(curr_k):\n",
    "                out, hiddens[i], _ = model.decode(beam[i][-1].view(1,1), hiddens[i], encoder_output,\n",
    "                                     encoder_mask)\n",
    "                logit,ind = torch.topk(out.squeeze(), curr_k, dim=0)\n",
    "                logits = torch.cat((logits,logit),0)\n",
    "                inds = torch.cat((inds,ind),0)\n",
    "            new_beam = []\n",
    "            new_beam_scores = []\n",
    "            new_hiddens = []\n",
    "            if curr_l==0:\n",
    "                for i in range(curr_k):\n",
    "                    max_ind = torch.argmax(nn.functional.log_softmax(logit,dim=0))\n",
    "                    new_beam_scores += [float(logit[max_ind])]\n",
    "                    logit[max_ind] = -1e9\n",
    "                    new_beam += [torch.cat((beam[0],ind[max_ind].unsqueeze(0)),0)]\n",
    "                    new_hiddens += [hiddens[0]]\n",
    "            else:\n",
    "                top_logits,top_inds_logit = torch.topk(torch.repeat_interleave(torch.Tensor(beam_scores).cuda(),\n",
    "                                                                               curr_k)\\\n",
    "                                                       +nn.functional.log_softmax(logits,dim=0),\n",
    "                                                       curr_k, dim=0)\n",
    "                for i in range(curr_k):\n",
    "                    if inds[top_inds_logit[i]]==eos_id:\n",
    "                        generations += [torch.cat((beam[top_inds_logit[i]//curr_k],inds[top_inds_logit[i]].unsqueeze(0)),0)]\n",
    "                        generations_scores+=[float(logits[top_inds_logit[i]])/(generations[-1].shape[0]**alpha)]\n",
    "                    else:\n",
    "                        new_beam += [torch.cat((beam[top_inds_logit[i]//curr_k],inds[top_inds_logit[i]].unsqueeze(0)),0)]\n",
    "                        new_hiddens += [hiddens[top_inds_logit[i]//curr_k]]\n",
    "                        new_beam_scores += [float(logits[top_inds_logit[i]])]\n",
    "            beam = new_beam\n",
    "            beam_scores = new_beam_scores\n",
    "            hiddens = new_hiddens\n",
    "        curr_l +=1\n",
    "    generations = [g for _, g in sorted(zip(generations_scores, generations))]\n",
    "    generations.reverse()\n",
    "    return [vocab.decode_sentence_from_ids(s.tolist()) for s in generations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "a4b8d71f-84c9-4cab-acf9-17b9d1b3b57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whose birth is a woman love\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['my love the sun upon thy love thy sphere .',\n",
       " 'i love the sun upon thy golden heart .',\n",
       " 'my love the sun upon thy love sheds',\n",
       " 'my love the sun upon thy love s sphere .',\n",
       " 'i love the sun upon thy love thy sphere .',\n",
       " 'i love the sun upon my love thy sphere .',\n",
       " 'i love the sun upon his golden love .',\n",
       " 'i love the sun upon his love thy sphere .',\n",
       " 'i love the sun upon thy love s sphere .',\n",
       " 'i love the sun upon thy golden love .',\n",
       " 'the sun upon whom thy love sheds',\n",
       " 'i love the sun upon her whose love .',\n",
       " 'i love the sun upon his love thy sphere . . .',\n",
       " 'i love the sun upon her love whose sphere .',\n",
       " 'i love the sun upon her love whose sphere . . .',\n",
       " 'i love the sun upon thy love whose sphere .',\n",
       " 'i love the sun upon my love my love .',\n",
       " 'my love the sun upon whose love s sphere',\n",
       " 'i love the sun upon his golden love s sphere',\n",
       " 'i love the sun upon her whose love s sphere',\n",
       " 'i love the sun upon my love love s sphere',\n",
       " 'i love the sun upon his love love s sphere',\n",
       " 'i love the sun upon thy golden heart bail',\n",
       " 'i love the sun upon thy love whose sphere . . .',\n",
       " 'i love the sun upon whose love s sphere',\n",
       " 'i love the sun upon thy golden love s sphere',\n",
       " 'i love the sun upon thy love s sphere . .',\n",
       " 'i love the sun upon her love s sphere',\n",
       " 'i love the sun upon my soul whose bride',\n",
       " 'i love the sun upon this love s sphere',\n",
       " 'i love the sun upon a love whose land',\n",
       " 'i love the sun upon his love s sphere',\n",
       " 'my love the sun upon thy love s sphere',\n",
       " 'my love the sun upon thy love thy sphere',\n",
       " 'my love the sun upon thy love decay',\n",
       " 'i love the sun upon my love s sphere',\n",
       " 'i love the sun upon a love s shade',\n",
       " 'i love the sun upon whose love s delight',\n",
       " 'i love the sun upon her love whose sphere',\n",
       " 'i love the sun upon thy love s sphere',\n",
       " 'i love the sun upon a love his land',\n",
       " 'i love the sun upon thy love whose sphere',\n",
       " 'i love the sun upon my love whose sphere',\n",
       " 'i love the sun upon thy golden heart',\n",
       " 'i love the sun upon thy love thy sphere',\n",
       " 'i love the sun upon this love s sun',\n",
       " 'i love the sun upon his love thy sphere',\n",
       " 'i love the sun upon his golden love',\n",
       " 'i love the sun upon thy love s sun',\n",
       " 'i love the sun upon my soul whose shadow',\n",
       " 'i love the sun upon a constant love',\n",
       " 'i love the sun upon thy golden love',\n",
       " 'i love the sun upon my love thy sphere',\n",
       " 'i love the sun upon her whose love',\n",
       " 'i love the sun upon my soul whose love',\n",
       " 'i love the sun upon my soul love',\n",
       " 'i love the sun upon thy soul love',\n",
       " 'i love the sun upon my love my love',\n",
       " 'i love the sun upon my love',\n",
       " 'my love the sun upon thy love']"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"WILLIAM SHAKESPEARE sep love moon bride sep tell me the love of comrades sweetens !\"\n",
    "print(predict_greedy(Erato_model, sentence, max_length=100))\n",
    "print()\n",
    "predict_beam(Erato_model, sentence, k=60, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b7a81-5122-4228-bda7-41a7167fbcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "3cfbb248-3d18-46f7-bfc6-e2c180a0d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WILLIAM SHAKESPEARE\n",
      "The Phoenix and the Turtle\n",
      "Renaissance\n",
      "\n",
      "Let the bird of loudest lay\n",
      "On the sole Arabian tree\n",
      "Herald sad and trumpet be,\n",
      "To whose sound chaste wings obey.\n",
      "\n",
      "But thou shrieking harbinger,\n",
      "Foul precurrer of the fiend,\n",
      "Augur of the fever's end,\n",
      "To this troop come thou not near.\n",
      "\n",
      "From this session interdict\n",
      "Every fowl of tyrant wing,\n",
      "Save the eagle, feather'd king;\n",
      "Keep the obsequy so strict.\n",
      "\n",
      "Let the priest in surplice white,\n",
      "That defunctive music can,\n",
      "Be the death-divining swan,\n",
      "Lest the requiem lack his right.\n",
      "\n",
      "And thou treble-dated crow,\n",
      "That thy sable gender mak'st\n",
      "With the breath thou giv'st and tak'st,\n",
      "'Mongst our mourners shalt thou go.\n",
      "\n",
      "Here the anthem doth commence:\n",
      "Love and constancy is dead;\n",
      "Phoenix and the Turtle fled\n",
      "In a mutual flame from hence.\n",
      "\n",
      "So they lov'd, as love in twain\n",
      "Had the essence but in one;\n",
      "Two distincts, division none:\n",
      "Number there in love was slain.\n",
      "\n",
      "Hearts remote, yet not asunder;\n",
      "Distance and no space was seen\n",
      "'Twixt this Turtle and his queen:\n",
      "But in them it were a wonder.\n",
      "\n",
      "So between them love did shine\n",
      "That the Turtle saw his right\n",
      "Flaming in the Phoenix' sight:\n",
      "Either was the other's mine.\n",
      "\n",
      "Property was thus appalled\n",
      "That the self was not the same;\n",
      "Single nature's double name\n",
      "Neither two nor one was called.\n",
      "\n",
      "Reason, in itself confounded,\n",
      "Saw division grow together,\n",
      "To themselves yet either neither,\n",
      "Simple were so well compounded;\n",
      "\n",
      "That it cried, \"How true a twain\n",
      "Seemeth this concordant one!\n",
      "Love has reason, reason none,\n",
      "If what parts can so remain.\"\n",
      "\n",
      "Whereupon it made this threne\n",
      "To the Phoenix and the Dove,\n",
      "Co-supremes and stars of love,\n",
      "As chorus to their tragic scene:\n",
      "\n",
      "                 threnos\n",
      "\n",
      "Beauty, truth, and rarity,\n",
      "Grace in all simplicity,\n",
      "Here enclos'd, in cinders lie.\n",
      "\n",
      "Death is now the Phoenix' nest,\n",
      "And the Turtle's loyal breast\n",
      "To eternity doth rest,\n",
      "\n",
      "Leaving no posterity:\n",
      "'Twas not their infirmity,\n",
      "It was married chastity.\n",
      "\n",
      "Truth may seem but cannot be;\n",
      "Beauty brag but 'tis not she;\n",
      "Truth and beauty buried be.\n",
      "\n",
      "To this urn let those repair\n",
      "That are either true or fair;\n",
      "For these dead birds sigh a prayer.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "p = data.iloc()[i]\n",
    "\n",
    "print(p['author'])\n",
    "print(p['poem name'])\n",
    "print(p['age'])\n",
    "print()\n",
    "print(p['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca76af-bcd4-4806-988a-0caf3148987a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
