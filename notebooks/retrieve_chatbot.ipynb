{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82044256-42af-45b4-90b5-20bae49e5dec",
   "metadata": {},
   "source": [
    "# Retrieve Chatbot\n",
    "## Chatbot using the Poly-encoder Transformer architecture (Humeau et al., 2019) for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4cb250-6201-46f9-9591-5665f85a1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is based on :\n",
    "# https://aritter.github.io/CS-7650/\n",
    "# This Project was developed at the Georgia Institute of Technology by Ashutosh Baheti (ashutosh.baheti@cc.gatech.edu), \n",
    "# borrowing  from the Neural Machine Translation Project (Project 2) \n",
    "# of the UC Berkeley NLP course https://cal-cs288.github.io/sp20/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cd56ac-bf9d-4fba-9b53-3779bae9b1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "import statistics\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import tqdm\n",
    "import nltk\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08146030-2203-46f6-a4c6-2ecdfd890757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from functools import partial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0899e5c-8afb-4f9f-a18b-3e442baa153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'distilbert-base-uncased' \n",
    "# Bert Imports\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "#bert_model = DistilBertModel.from_pretrained(bert_model_name)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(bert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d822980-0adf-46b8-bf5e-7a37f56c5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def make_dir_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        logging.info(\"Creating new directory: {}\".format(directory))\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def print_list(l, K=None):\n",
    "    # If K is given then only print first K\n",
    "    for i, e in enumerate(l):\n",
    "        if i == K:\n",
    "            break\n",
    "        print(e)\n",
    "    print()\n",
    "\n",
    "def remove_multiple_spaces(string):\n",
    "    return re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "def save_in_pickle(save_object, save_file):\n",
    "    with open(save_file, \"wb\") as pickle_out:\n",
    "        pickle.dump(save_object, pickle_out)\n",
    "\n",
    "def load_from_pickle(pickle_file):\n",
    "    with open(pickle_file, \"rb\") as pickle_in:\n",
    "        return pickle.load(pickle_in)\n",
    "\n",
    "def save_in_txt(list_of_strings, save_file):\n",
    "    with open(save_file, \"w\") as writer:\n",
    "        for line in list_of_strings:\n",
    "            line = line.strip()\n",
    "            writer.write(f\"{line}\\n\")\n",
    "\n",
    "def load_from_txt(txt_file):\n",
    "    with open(txt_file, \"r\") as reader:\n",
    "        all_lines = list()\n",
    "        for line in reader:\n",
    "            line = line.strip()\n",
    "            all_lines.append(line)\n",
    "        return all_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46009df-e3c4-4528-baf3-ddf8e7a94748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61cc3b-c4b9-4498-8cc7-fd86792045fd",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c4729-5acc-4dd2-b29a-22a96bcde6c7",
   "metadata": {},
   "source": [
    "### Cornell Movie Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82996006-9d05-4822-922c-3c22d7ae5db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Conversation Pairs = 53065\n",
      "Number of Evaluation Conversation Pairs = 100\n"
     ]
    }
   ],
   "source": [
    "# Loading the pre-processed conversational exchanges (source-target pairs) from pickle data files\n",
    "all_conversations = load_from_pickle(\"../data/cornell_movie/processed_CMDC.pkl\")\n",
    "# Extract 100 conversations from the end for evaluation and keep the rest for training\n",
    "eval_conversations = all_conversations[-100:]\n",
    "all_conversations = all_conversations[:-100]\n",
    "\n",
    "# Logging data stats\n",
    "print(f\"Number of Training Conversation Pairs = {len(all_conversations)}\")\n",
    "print(f\"Number of Evaluation Conversation Pairs = {len(eval_conversations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a4475-3b17-43dc-ae3c-e837631ace29",
   "metadata": {},
   "source": [
    "#### Building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f575092-995c-4d5d-bd8a-767b7843a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the vocabulary = 7727\n"
     ]
    }
   ],
   "source": [
    "pad_word = \"<pad>\"\n",
    "bos_word = \"<s>\"\n",
    "eos_word = \"</s>\"\n",
    "unk_word = \"<unk>\"\n",
    "pad_id = 0\n",
    "bos_id = 1\n",
    "eos_id = 2\n",
    "unk_id = 3\n",
    "    \n",
    "def normalize_sentence(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word_to_id = {pad_word: pad_id, bos_word: bos_id, eos_word:eos_id, unk_word: unk_id}\n",
    "        self.word_count = {}\n",
    "        self.id_to_word = {pad_id: pad_word, bos_id: bos_word, eos_id: eos_word, unk_id: unk_word}\n",
    "        self.num_words = 4\n",
    "    \n",
    "    def get_ids_from_sentence(self, sentence):\n",
    "        sentence = normalize_sentence(sentence)\n",
    "        sent_ids = [bos_id] + [self.word_to_id[word] if word in self.word_to_id \\\n",
    "                               else unk_id for word in sentence.split()] + \\\n",
    "                               [eos_id]\n",
    "        return sent_ids\n",
    "    \n",
    "    def tokenized_sentence(self, sentence):\n",
    "        sent_ids = self.get_ids_from_sentence(sentence)\n",
    "        return [self.id_to_word[word_id] for word_id in sent_ids]\n",
    "\n",
    "    def decode_sentence_from_ids(self, sent_ids):\n",
    "        words = list()\n",
    "        for i, word_id in enumerate(sent_ids):\n",
    "            if word_id in [bos_id, eos_id, pad_id]:\n",
    "                # Skip these words\n",
    "                continue\n",
    "            else:\n",
    "                words.append(self.id_to_word[word_id])\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def add_words_from_sentence(self, sentence):\n",
    "        sentence = normalize_sentence(sentence)\n",
    "        for word in sentence.split():\n",
    "            if word not in self.word_to_id:\n",
    "                # add this word to the vocabulary\n",
    "                self.word_to_id[word] = self.num_words\n",
    "                self.id_to_word[self.num_words] = word\n",
    "                self.word_count[word] = 1\n",
    "                self.num_words += 1\n",
    "            else:\n",
    "                # update the word count\n",
    "                self.word_count[word] += 1\n",
    "\n",
    "vocab = Vocabulary()\n",
    "for src, tgt in all_conversations:\n",
    "    vocab.add_words_from_sentence(src)\n",
    "    vocab.add_words_from_sentence(tgt)\n",
    "print(f\"Total words in the vocabulary = {vocab.num_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcad31b-c09b-4c05-b9fe-599aae7a5e61",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492e0e75-433b-4b36-ba79-e621aeffa2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTurnMovieDialog_dataset(Dataset):\n",
    "    \"\"\"Single-Turn version of Cornell Movie Dialog Cropus dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, conversations, vocab, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            conversations: list of tuple (src_string, tgt_string) \n",
    "                         - src_string: String of the source sentence\n",
    "                         - tgt_string: String of the target sentence\n",
    "            vocab: Vocabulary object that contains the mapping of \n",
    "                    words to indices\n",
    "            device: cpu or cuda\n",
    "        \"\"\"\n",
    "        self.conversations = conversations\n",
    "        self.vocab = vocab\n",
    "        self.device = device\n",
    "\n",
    "        def encode(src, tgt):\n",
    "            src_ids = self.vocab.get_ids_from_sentence(src)\n",
    "            tgt_ids = self.vocab.get_ids_from_sentence(tgt)\n",
    "            return (src_ids, tgt_ids)\n",
    "\n",
    "        # We will pre-tokenize the conversations and save in id lists for later use\n",
    "        self.tokenized_conversations = [encode(src, tgt) for src, tgt in self.conversations]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.conversations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return {\"conv_ids\":self.tokenized_conversations[idx], \"conv\":self.conversations[idx]}\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (src_seq, tgt_seq).\n",
    "    We should build a custom collate_fn rather than using default collate_fn,\n",
    "    because merging sequences (including padding) is not supported in default.\n",
    "    Seqeuences are padded to the maximum length of mini-batch sequences (dynamic padding).\n",
    "    Args:\n",
    "        data: list of dicts {\"conv_ids\":(src_ids, tgt_ids), \"conv\":(src_str, trg_str)}.\n",
    "            - src_ids: list of src piece ids; variable length.\n",
    "            - tgt_ids: list of tgt piece ids; variable length.\n",
    "            - src_str: String of src\n",
    "            - tgt_str: String of tgt\n",
    "    Returns: dict { \"conv_ids\":     (src_ids, tgt_ids), \n",
    "                    \"conv\":         (src_str, tgt_str), \n",
    "                    \"conv_tensors\": (src_seqs, tgt_seqs)}\n",
    "            src_seqs: torch tensor of shape (src_padded_length, batch_size).\n",
    "            tgt_seqs: torch tensor of shape (tgt_padded_length, batch_size).\n",
    "            src_padded_length = length of the longest src sequence from src_ids\n",
    "            tgt_padded_length = length of the longest tgt sequence from tgt_ids\n",
    "    \"\"\"\n",
    "    # Sort conv_ids based on decreasing order of the src_lengths.\n",
    "    # This is required for efficient GPU computations.\n",
    "    src_ids = [torch.LongTensor(e[\"conv_ids\"][0]) for e in data]\n",
    "    tgt_ids = [torch.LongTensor(e[\"conv_ids\"][1]) for e in data]\n",
    "    src_str = [e[\"conv\"][0] for e in data]\n",
    "    tgt_str = [e[\"conv\"][1] for e in data]\n",
    "    data = list(zip(src_ids, tgt_ids, src_str, tgt_str))\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    src_ids, tgt_ids, src_str, tgt_str = zip(*data)\n",
    "\n",
    "\n",
    "    # Pad the src_ids and tgt_ids using token pad_id to create src_seqs and tgt_seqs\n",
    "    \n",
    "    # Implementation tip: You can use the nn.utils.rnn.pad_sequence utility\n",
    "    # function to combine a list of variable-length sequences with padding.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    src_seqs = nn.utils.rnn.pad_sequence(src_ids, padding_value = pad_id,\n",
    "                                         batch_first = False)\n",
    "    tgt_seqs = nn.utils.rnn.pad_sequence(tgt_ids, padding_value = pad_id, \n",
    "                                         batch_first = False)\n",
    "    \n",
    "    src_padded_length = len(src_seqs[0])\n",
    "    tgt_padded_length = len(tgt_seqs[0])\n",
    "    return {\"conv_ids\":(src_ids, tgt_ids), \"conv\":(src_str, tgt_str), \"conv_tensors\":(src_seqs.to(device), tgt_seqs.to(device))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4165dc63-5101-410e-a14e-8c0ec48456b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for all_conversations\n",
    "dataset = SingleTurnMovieDialog_dataset(all_conversations, vocab, device)\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                               shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea6c84cc-47d2-499b-83e6-6dcf9cb82d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_collate_fn(batch, tokenizer):\n",
    "    bert_vocab = tokenizer.get_vocab()\n",
    "    bert_pad_token = bert_vocab['[PAD]']\n",
    "    bert_unk_token = bert_vocab['[UNK]']\n",
    "    bert_cls_token = bert_vocab['[CLS]']\n",
    "\n",
    "    inputs, masks_input, outputs, masks_output = [], [], [], []\n",
    "    for data in batch:\n",
    "        tokenizer_input = tokenizer([data[0]])\n",
    "        tokenized_sent = tokenizer_input['input_ids'][0]\n",
    "        mask_input = tokenizer_input['attention_mask'][0]\n",
    "        inputs.append(torch.tensor(tokenized_sent))\n",
    "        tokenizer_output = tokenizer([data[0]])\n",
    "        tokenized_sent = tokenizer_output['input_ids'][0]\n",
    "        mask_output = tokenizer_output['attention_mask'][0]\n",
    "        outputs.append(torch.tensor(tokenized_sent))\n",
    "        masks_input.append(torch.tensor(mask_input))\n",
    "        masks_output.append(torch.tensor(mask_output))\n",
    "    inputs = pad_sequence(inputs, batch_first=True, padding_value=bert_pad_token)\n",
    "    outputs = pad_sequence(outputs, batch_first=True, padding_value=bert_pad_token)\n",
    "    masks_input = pad_sequence(masks_input, batch_first=True, padding_value=0.0)\n",
    "    masks_output = pad_sequence(masks_output, batch_first=True, padding_value=0.0)\n",
    "    return inputs, masks_input, outputs, masks_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4310c2-d554-4801-865f-2a237582058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pytorch dataloaders from train_dataset, val_dataset, and test_datset\n",
    "train_dataloader = DataLoader(all_conversations,batch_size=batch_size,collate_fn=partial(transformer_collate_fn, tokenizer=tokenizer), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066ffc35-7a80-4e4c-90f1-f7e25e25d6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 2059, 2008, 1055, 2035, 2017, 2018, 2000, 2360, 1012,  102])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_collate_fn(all_conversations[0:10],tokenizer)[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc6414a-8a86-40a8-9d8a-78acb72407fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'then that s all you had to say.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(transformer_collate_fn(all_conversations[0:10],tokenizer)[0][5], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8628cdb-1f19-4927-9e03-58433f43f080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there.',\n",
       " 'you have my word. as a gentleman',\n",
       " 'hi.',\n",
       " 'have fun tonight?',\n",
       " 'well no...',\n",
       " 'then that s all you had to say.',\n",
       " 'but',\n",
       " 'do you listen to this crap?',\n",
       " 'what good stuff?',\n",
       " 'wow']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(transformer_collate_fn(all_conversations[0:10],tokenizer)[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45eb8b7-c31b-4dae-aa42-ba06fe081fa8",
   "metadata": {},
   "source": [
    "## Polyencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71d0e7d2-52bb-4aaf-ad20-27cd452f0d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#bert1 = DistilBertModel.from_pretrained(bert_model_name)\n",
    "#bert2 = DistilBertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "bert = DistilBertModel.from_pretrained(bert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da94557e-4d2f-4bc7-bd3a-d408ebf42569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double Bert\n",
    "class RetrieverPolyencoder(nn.Module):\n",
    "    def __init__(self, contextBert, candidateBert, vocab, max_len = 300, hidden_dim = 768, out_dim = 64, num_layers = 2, dropout=0.1, device=device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_len = max_len\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        # Context layers\n",
    "        self.contextBert = contextBert\n",
    "        self.contextDropout = nn.Dropout(dropout)\n",
    "        self.contextFc = nn.Linear(self.hidden_dim, self.out_dim)\n",
    "        \n",
    "        # Candidates layers\n",
    "        self.candidatesBert = candidateBert\n",
    "        self.pos_emb = nn.Embedding(self.max_len, self.hidden_dim)\n",
    "        self.candidatesDropout = nn.Dropout(dropout)\n",
    "        self.candidatesFc = nn.Linear(self.hidden_dim, self.out_dim)\n",
    "        \n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def attention(self, q, k, v, vMask=None):\n",
    "        w = torch.matmul(q, k.transpose(-1, -2))\n",
    "        if vMask is not None:\n",
    "            w *= vMask.unsqueeze(1)\n",
    "            w = F.softmax(w, -1)\n",
    "        w = self.att_dropout(w)\n",
    "        score = torch.matmul(w, v)\n",
    "        return score\n",
    "\n",
    "    def score(self, context, context_mask, responses, responses_mask):\n",
    "        \"\"\"Run the model on the source and compute the loss on the target.\n",
    "\n",
    "        Args:\n",
    "            source: An integer tensor with shape (max_source_sequence_length,\n",
    "                batch_size) containing subword indices for the source sentences.\n",
    "            target: An integer tensor with shape (max_target_sequence_length,\n",
    "                batch_size) containing subword indices for the target sentences.\n",
    "\n",
    "        Returns:\n",
    "            A scalar float tensor representing cross-entropy loss on the current batch\n",
    "            divided by the number of target tokens in the batch.\n",
    "            Many of the target tokens will be pad tokens. You should mask the loss \n",
    "            from these tokens using appropriate mask on the target tokens loss.\n",
    "        \"\"\"\n",
    "        batch_size, nb_cand, seq_len = responses.shape\n",
    "        # Context\n",
    "        context_encoded = self.contextBert(context,context_mask)[-1]\n",
    "        pos_emb = self.pos_emb(torch.arange(self.max_len).to(self.device))\n",
    "        context_att = self.attention(pos_emb, context_encoded, context_encoded, context_mask)\n",
    "\n",
    "        # Response\n",
    "        responses_encoded = self.candidatesBert(responses.view(-1,responses.shape[2]), responses_mask.view(-1,responses.shape[2]))[-1][:,0,:]\n",
    "        responses_encoded = responses_encoded.view(batch_size,nb_cand,-1)\n",
    "        \n",
    "        context_emb = self.attention(responses_encoded, context_att, context_att).squeeze() \n",
    "        dot_product = (context_emb*responses_encoded).sum(-1)\n",
    "        \n",
    "        return dot_product\n",
    "\n",
    "    \n",
    "    def compute_loss(self, context, context_mask, response, response_mask):\n",
    "        \"\"\"Run the model on the source and compute the loss on the target.\n",
    "\n",
    "        Args:\n",
    "            source: An integer tensor with shape (max_source_sequence_length,\n",
    "                batch_size) containing subword indices for the source sentences.\n",
    "            target: An integer tensor with shape (max_target_sequence_length,\n",
    "                batch_size) containing subword indices for the target sentences.\n",
    "\n",
    "        Returns:\n",
    "            A scalar float tensor representing cross-entropy loss on the current batch\n",
    "            divided by the number of target tokens in the batch.\n",
    "            Many of the target tokens will be pad tokens. You should mask the loss \n",
    "            from these tokens using appropriate mask on the target tokens loss.\n",
    "        \"\"\"\n",
    "        batch_size = context.shape[0]\n",
    "        \n",
    "        # Context\n",
    "        context_encoded = self.contextBert(context,context_mask)[-1]\n",
    "        pos_emb = self.pos_emb(torch.arange(self.max_len).to(self.device))\n",
    "        context_att = self.attention(pos_emb, context_encoded, context_encoded, context_mask)\n",
    "\n",
    "        # Response\n",
    "        response_encoded = self.candidatesBert(response, response_mask)[-1][:,0,:]\n",
    "        \n",
    "        response_encoded = response_encoded.unsqueeze(0).expand(batch_size, batch_size, response_encoded.shape[1]) \n",
    "        context_emb = self.attention(response_encoded, context_att, context_att).squeeze() \n",
    "        dot_product = (context_emb*response_encoded).sum(-1)\n",
    "        mask = torch.eye(batch_size).to(self.device)\n",
    "        loss = F.log_softmax(dot_product, dim=-1) * mask\n",
    "        loss = (-loss.sum(dim=1)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bec60582-2c65-4093-bf9a-5d0c92e24063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Bert\n",
    "class RetrieverPolyencoder_single(nn.Module):\n",
    "    def __init__(self, bert, max_len = 300, hidden_dim = 768, out_dim = 64, num_layers = 2, dropout=0.1, device=device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_len = max_len\n",
    "        self.out_dim = out_dim\n",
    "        self.bert = bert\n",
    "        \n",
    "        # Context layers\n",
    "        self.contextDropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Candidates layers\n",
    "        self.pos_emb = nn.Embedding(self.max_len, self.hidden_dim)\n",
    "        self.candidatesDropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def attention(self, q, k, v, vMask=None):\n",
    "        w = torch.matmul(q, k.transpose(-1, -2))\n",
    "        if vMask is not None:\n",
    "            w *= vMask.unsqueeze(1)\n",
    "            w = F.softmax(w, -1)\n",
    "        w = self.att_dropout(w)\n",
    "        score = torch.matmul(w, v)\n",
    "        return score\n",
    "\n",
    "    def score(self, context, context_mask, responses, responses_mask):\n",
    "        \"\"\"Run the model on the source and compute the loss on the target.\n",
    "\n",
    "        Args:\n",
    "            source: An integer tensor with shape (max_source_sequence_length,\n",
    "                batch_size) containing subword indices for the source sentences.\n",
    "            target: An integer tensor with shape (max_target_sequence_length,\n",
    "                batch_size) containing subword indices for the target sentences.\n",
    "\n",
    "        Returns:\n",
    "            A scalar float tensor representing cross-entropy loss on the current batch\n",
    "            divided by the number of target tokens in the batch.\n",
    "            Many of the target tokens will be pad tokens. You should mask the loss \n",
    "            from these tokens using appropriate mask on the target tokens loss.\n",
    "        \"\"\"\n",
    "        batch_size, nb_cand, seq_len = responses.shape\n",
    "        # Context\n",
    "        context_encoded = self.bert(context,context_mask)[0][:,0,:]\n",
    "        pos_emb = self.pos_emb(torch.arange(self.max_len).to(self.device))\n",
    "        context_att = self.attention(pos_emb, context_encoded, context_encoded, context_mask)\n",
    "\n",
    "        # Response\n",
    "        responses_encoded = self.bert(responses.view(-1,responses.shape[2]), responses_mask.view(-1,responses.shape[2]))[0][:,0,:]\n",
    "        responses_encoded = responses_encoded.view(batch_size,nb_cand,-1)\n",
    "        response_encoded = self.candidatesFc(response_encoded)\n",
    "        \n",
    "        context_emb = self.attention(responses_encoded, context_att, context_att).squeeze() \n",
    "        dot_product = (context_emb*responses_encoded).sum(-1)\n",
    "        \n",
    "        return dot_product\n",
    "\n",
    "    \n",
    "    def compute_loss(self, context, context_mask, response, response_mask):\n",
    "        \"\"\"Run the model on the source and compute the loss on the target.\n",
    "\n",
    "        Args:\n",
    "            source: An integer tensor with shape (max_source_sequence_length,\n",
    "                batch_size) containing subword indices for the source sentences.\n",
    "            target: An integer tensor with shape (max_target_sequence_length,\n",
    "                batch_size) containing subword indices for the target sentences.\n",
    "\n",
    "        Returns:\n",
    "            A scalar float tensor representing cross-entropy loss on the current batch\n",
    "            divided by the number of target tokens in the batch.\n",
    "            Many of the target tokens will be pad tokens. You should mask the loss \n",
    "            from these tokens using appropriate mask on the target tokens loss.\n",
    "        \"\"\"\n",
    "        batch_size = context.shape[0]\n",
    "        seq_len = response.shape[1]\n",
    "        \n",
    "        # Context\n",
    "        context_encoded = self.bert(context,context_mask)[0][:,0,:]\n",
    "        pos_emb = self.pos_emb(torch.arange(self.max_len).to(self.device))\n",
    "        context_att = self.attention(pos_emb, context_encoded, context_encoded, context_mask)\n",
    "\n",
    "        # Response\n",
    "        print(response.shape)\n",
    "        response_encoded = self.bert(response, response_mask)[0][:,0,:]\n",
    "        print(response_encoded.shape)\n",
    "        response_encoded = response_encoded.view(batch_size, -1)\n",
    "\n",
    "        \n",
    "        response_encoded = response_encoded.unsqueeze(0).expand(batch_size, batch_size, response_encoded.shape[1]) \n",
    "        context_emb = self.attention(response_encoded, context_att, context_att).squeeze() \n",
    "        dot_product = (context_emb*response_encoded).sum(-1)\n",
    "        mask = torch.eye(batch_size).to(self.device)\n",
    "        loss = F.log_softmax(dot_product, dim=-1) * mask\n",
    "        loss = (-loss.sum(dim=1)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13d9431f-ca82-4895-9d22-2a59d8e8b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-encoder\n",
    "class RetrieverBiencoder(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        \n",
    "    def score(self, context, context_mask, responses, responses_mask):\n",
    "\n",
    "        context_vec = self.bert(context, context_mask)[0][:,0,:]  # [bs,dim]\n",
    "\n",
    "        batch_size, res_length = response.shape\n",
    "\n",
    "        responses_vec = self.bert(responses_input_ids, responses_input_masks)[0][:,0,:]  # [bs,dim]\n",
    "        responses_vec = responses_vec.view(batch_size, 1, -1)\n",
    "\n",
    "        responses_vec = responses_vec.squeeze(1)        \n",
    "        context_vec = context_vec.unsqueeze(1)\n",
    "        dot_product = torch.matmul(context_vec, responses_vec.permute(0, 2, 1)).squeeze()\n",
    "        return dot_product\n",
    "    \n",
    "    def compute_loss(self, context, context_mask, response, response_mask):\n",
    "\n",
    "        context_vec = self.bert(context, context_mask)[0]  # [bs,dim]\n",
    "\n",
    "        batch_size, res_length = response.shape\n",
    "\n",
    "        responses_vec = self.bert(response, response_mask)[0][:,0,:]  # [bs,dim]\n",
    "        #responses_vec = responses_vec.view(batch_size, 1, -1)\n",
    "        \n",
    "        print(context_vec.shape)\n",
    "        print(responses_vec.shape)\n",
    "\n",
    "        responses_vec = responses_vec.squeeze(1)\n",
    "        dot_product = torch.matmul(context_vec, responses_vec.t())  # [bs, bs]\n",
    "        mask = torch.eye(context.size(0)).to(context_mask.device)\n",
    "        loss = F.log_softmax(dot_product, dim=-1) * mask\n",
    "        loss = (-loss.sum(dim=1)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44cce345-ca8d-4f67-af25-119557a78eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, num_epochs, model_file, learning_rate=0.0001):\n",
    "    \"\"\"Train the model for given µnumber of epochs and save the trained model in \n",
    "    the final model_file.\n",
    "    \"\"\"\n",
    "\n",
    "    decoder_learning_ratio = 5.0\n",
    "    #encoder_parameter_names = ['word_embedding', 'encoder']\n",
    "    encoder_parameter_names = ['encode_emb', 'encode_gru', 'l1', 'l2']\n",
    "                           \n",
    "    encoder_named_params = list(filter(lambda kv: any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
    "    decoder_named_params = list(filter(lambda kv: not any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
    "    encoder_params = [e[1] for e in encoder_named_params]\n",
    "    decoder_params = [e[1] for e in decoder_named_params]\n",
    "    optimizer = torch.optim.AdamW([{'params': encoder_params},\n",
    "                {'params': decoder_params, 'lr': learning_rate * decoder_learning_ratio}], lr=learning_rate)\n",
    "    \n",
    "    clip = 50.0\n",
    "    for epoch in tqdm.notebook.trange(num_epochs, desc=\"training\", unit=\"epoch\"):\n",
    "        # print(f\"Total training instances = {len(train_dataset)}\")\n",
    "        # print(f\"train_data_loader = {len(train_data_loader)} {1180 > len(train_data_loader)/20}\")\n",
    "        with tqdm.notebook.tqdm(\n",
    "                data_loader,\n",
    "                desc=\"epoch {}\".format(epoch + 1),\n",
    "                unit=\"batch\",\n",
    "                total=len(data_loader)) as batch_iterator:\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for i, batch_data in enumerate(batch_iterator, start=1):\n",
    "                source, source_mask, target, target_mask = batch_data\n",
    "                optimizer.zero_grad()\n",
    "                loss = model.compute_loss(source.cuda(), source_mask.cuda(), target.cuda(), target_mask.cuda())\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                # Gradient clipping before taking the step\n",
    "                _ = nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item())\n",
    "    # Save the model after training         \n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cb8fef6-e77d-4b2b-9e60-24882010d181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dd9b6cbc14491eb3fae68dd9a331cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64589ab8597a4b899ec3c97d9594f672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 13, 768])\n",
      "torch.Size([32, 13, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_744/176886743.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbaseline_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetrieverBiencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline_model.pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Download the trained model to local for future use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#files.download('baseline_model.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_744/769372122.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, num_epochs, model_file, learning_rate)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_744/2475319877.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, context, context_mask, response, response_mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mresponses_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponses_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [bs, bs]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_product\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "# You are welcome to adjust these parameters based on your model implementation.\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "# Reloading the data_loader to increase batch_size\n",
    "train_dataloader = DataLoader(all_conversations[0:2800],batch_size=batch_size,collate_fn=partial(transformer_collate_fn, tokenizer=tokenizer), shuffle = True)\n",
    "\n",
    "baseline_model = RetrieverBiencoder(bert).to(device)\n",
    "train(baseline_model, train_dataloader, num_epochs, \"baseline_model.pt\",learning_rate=learning_rate)\n",
    "# Download the trained model to local for future use\n",
    "#files.download('baseline_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45c1235e-e9b3-455e-83a1-28f1d268537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = RetrieverPolyencoder(bert1,bert2,vocab).to(device)\n",
    "baseline_model.load_state_dict(torch.load(\"baseline_model3.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4c8083a-028d-4f00-a99d-5ae2123f4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = transformer_collate_fn(all_conversations[0:100],tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51551d4c-3e33-4db4-bf78-77d55e2a64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffe6d116-3af8-4657-a420-1d2dd02710bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = baseline_model.score(vals[0][i].unsqueeze(0).cuda(),vals[1][i].unsqueeze(0).cuda(),vals[2].unsqueeze(0).cuda(),vals[3].unsqueeze(0).cuda()).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bd57cbc-a87e-4d0f-b77b-48a4c5f7b26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have fun tonight ?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conversations[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd484740-e9e9-4fe4-a23b-8a67a12791cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they do not !'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conversations[np.argmax(scores)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91c9697b-9b5c-412c-aad8-d21c2cf61c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there .\n",
      "get her to act like a human\n",
      "\n",
      "you have my word . as a gentleman\n",
      "you set me up .\n",
      "\n",
      "hi .\n",
      "funny you re the only one\n",
      "\n",
      "have fun tonight ?\n",
      "oh right . friday .\n",
      "\n",
      "well no . . .\n",
      "so they tell me . . .\n",
      "\n",
      "then that s all you had to say .\n",
      "it s off . the whole thing .\n",
      "\n",
      "but\n",
      "seven thirty ?\n",
      "\n",
      "do you listen to this crap ?\n",
      "not at all\n",
      "\n",
      "what good stuff ?\n",
      "how many people go here ?\n",
      "\n",
      "wow\n",
      "my father wouldn t approve of that that\n",
      "\n",
      "she okay ?\n",
      "funny you re the only one\n",
      "\n",
      "they do to !\n",
      "you re sweet .\n",
      "\n",
      "did you change your hair ?\n",
      "your sister here ?\n",
      "\n",
      "no .\n",
      "thirty two .\n",
      "\n",
      "who ?\n",
      "so they tell me . . .\n",
      "\n",
      "great\n",
      "north actually . how d you ?\n",
      "\n",
      "it s more\n",
      "but\n",
      "\n",
      "where ve you been ?\n",
      "then why d you ask ?\n",
      "\n",
      "what ?\n",
      "so what s your excuse ?\n",
      "\n",
      "in th . for a month\n",
      "pleasant ?\n",
      "\n",
      "why ?\n",
      "how many people go here ?\n",
      "\n",
      "he was like a total babe\n",
      "try lookin at it from this angle\n",
      "\n",
      "you looked beautiful last night you know .\n",
      "maybe .\n",
      "\n",
      "let go !\n",
      "were you in jail ?\n",
      "\n",
      "you set me up .\n",
      "you re sweet .\n",
      "\n",
      "but she doesn t want to date .\n",
      "then that s all you had to say .\n",
      "\n",
      "daddy i\n",
      "sure i do\n",
      "\n",
      "oh god . it s starting .\n",
      "i m fine . i m\n",
      "\n",
      "daddy no !\n",
      "what ?\n",
      "\n",
      "why ?\n",
      "no you weren t\n",
      "\n",
      "the prom ? kat has a date ?\n",
      "you wanna go out with him ?\n",
      "\n",
      "you the new guy ?\n",
      "you don t care if i die\n",
      "\n",
      "so which dakota you from ?\n",
      "are you lost ?\n",
      "\n",
      "north actually . how d you ?\n",
      "they do not !\n",
      "\n",
      "how many people were in your old school ?\n",
      "he was like a total babe\n",
      "\n",
      "thirty two .\n",
      "you re sweet .\n",
      "\n",
      "get out !\n",
      "away .\n",
      "\n",
      "how many people go here ?\n",
      "try lookin at it from this angle\n",
      "\n",
      "what about him ?\n",
      "let s go .\n",
      "\n",
      "it s a lung cancer issue\n",
      "and where re you going ?\n",
      "\n",
      "her favorite uncle\n",
      "that s what you want isn t it ?\n",
      "\n",
      "he s pretty !\n",
      "we don t chat .\n",
      "\n",
      "cameron i m a little busy\n",
      "why ?\n",
      "\n",
      "cameron do you like the girl ?\n",
      "north actually . how d you ?\n",
      "\n",
      "sure\n",
      "i just need to lie down for awhile\n",
      "\n",
      "she kissed me .\n",
      "i just need to lie down for awhile\n",
      "\n",
      "what s the worst ?\n",
      "are you lost ?\n",
      "\n",
      "hey do you mind ?\n",
      "seven thirty ?\n",
      "\n",
      "where ya goin ?\n",
      "where ?\n",
      "\n",
      "away .\n",
      "so they tell me . . .\n",
      "\n",
      "leave my sister alone .\n",
      "no fear .\n",
      "\n",
      "yeah\n",
      "do what ?\n",
      "\n",
      "you just said\n",
      "because she ll scare them away .\n",
      "\n",
      "what ?\n",
      "you re sweet .\n",
      "\n",
      "a hundred bucks a date .\n",
      "but\n",
      "\n",
      "forget it .\n",
      "then go get her\n",
      "\n",
      "it s about time .\n",
      "bianca\n",
      "\n",
      "how d you do it ?\n",
      "joey .\n",
      "\n",
      "do what ?\n",
      "i m gettin there\n",
      "\n",
      "hey .\n",
      "funny you re the only one\n",
      "\n",
      "are you lost ?\n",
      "do what ?\n",
      "\n",
      "nope just came by to chat\n",
      "a deal s a deal .\n",
      "\n",
      "i hear you re helpin verona .\n",
      "oh right . friday .\n",
      "\n",
      "uh yeah . we re old friend\n",
      "sure i do\n",
      "\n",
      "he always look so\n",
      "uh yeah . we re old friend\n",
      "\n",
      "william didn t even go to high school\n",
      "were you in jail ?\n",
      "\n",
      "you think this ll work ?\n",
      "would you mind getting me a drink cameron ?\n",
      "\n",
      "what d he say ?\n",
      "you wanna go out with him ?\n",
      "\n",
      "have you seen him ?\n",
      "forget it . i m stayin .\n",
      "\n",
      "who ?\n",
      "that s never been proven\n",
      "\n",
      "pick you up friday then\n",
      "a deal s a deal .\n",
      "\n",
      "you covered in my vomit .\n",
      "exactly my point\n",
      "\n",
      "excuse me ?\n",
      "just for a minute\n",
      "\n",
      "i say do what you wanna do .\n",
      "maybe .\n",
      "\n",
      "okay ?\n",
      "what crap ?\n",
      "\n",
      "you re not okay .\n",
      "this .\n",
      "\n",
      "why re you doing this ?\n",
      "you know what they say\n",
      "\n",
      "i told you\n",
      "thirty two .\n",
      "\n",
      "you don t care if i die\n",
      "your sister here ?\n",
      "\n",
      "sure i do\n",
      "the real you .\n",
      "\n",
      "why d you let him get to you ?\n",
      "oh right . friday .\n",
      "\n",
      "i thought you were above all that\n",
      "no but\n",
      "\n",
      "kat ! wake up !\n",
      "looks like things worked out tonight huh ?\n",
      "\n",
      "busy\n",
      "her favorite uncle\n",
      "\n",
      "were you in jail ?\n",
      "dead at forty one .\n",
      "\n",
      "maybe .\n",
      "you don t care if i die\n",
      "\n",
      "no you weren t\n",
      "in th . for a month\n",
      "\n",
      "then why d you ask ?\n",
      "forget it . i m stayin .\n",
      "\n",
      "i should do this .\n",
      "it s just a party . daddy .\n",
      "\n",
      "do what ?\n",
      "oh right . friday .\n",
      "\n",
      "start a band ?\n",
      "no you weren t\n",
      "\n",
      "oh so now you think you know me ?\n",
      "what ?\n",
      "\n",
      "who ?\n",
      "so they tell me . . .\n",
      "\n",
      "what are you doing here ?\n",
      "and where re you going ?\n",
      "\n",
      "i heard there was a poetry reading .\n",
      "uh yeah . we re old friend\n",
      "\n",
      "you re so\n",
      "that s what you want isn t it ?\n",
      "\n",
      "c mon . it s not that bad\n",
      "looks like things worked out tonight huh ?\n",
      "\n",
      "put your right foot there\n",
      "get her to act like a human\n",
      "\n",
      "a soft side ? who knew ?\n",
      "but\n",
      "\n",
      "yeah well don t let it get out\n",
      "you might wanna think about it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_v = 100\n",
    "vals = transformer_collate_fn(all_conversations[0:max_v],tokenizer)\n",
    "correct = 0\n",
    "for i in range(max_v):\n",
    "    scores = baseline_model.score(vals[0][i].unsqueeze(0).cuda(),vals[1][i].unsqueeze(0).cuda(),vals[2].unsqueeze(0).cuda(),vals[3].unsqueeze(0).cuda()).detach().cpu().numpy()\n",
    "    if np.argmax(scores)==i:\n",
    "        correct+=1\n",
    "    print(all_conversations[i][0])\n",
    "    print(all_conversations[np.argmax(scores)][1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcb31bb6-3562-4fad-80af-3d5a79a3a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(correct/max_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1ce7a-c19b-424d-a51d-ec68cf8bcae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
