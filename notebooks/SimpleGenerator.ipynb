{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbf34a7-a58e-49a2-aa4b-8bca5f58c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "import statistics\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cedf6f-e5e8-4d3f-8d91-7e3d843b11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dir_if_not_exists(directory):\n",
    "\tif not os.path.exists(directory):\n",
    "\t\tlogging.info(\"Creating new directory: {}\".format(directory))\n",
    "\t\tos.makedirs(directory)\n",
    "\n",
    "def print_list(l, K=None):\n",
    "\tfor i, e in enumerate(l):\n",
    "\t\tif i == K:\n",
    "\t\t\tbreak\n",
    "\t\tprint(e)\n",
    "\tprint()\n",
    "\n",
    "def remove_multiple_spaces(string):\n",
    "\treturn re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "def save_in_pickle(save_object, save_file):\n",
    "\twith open(save_file, \"wb\") as pickle_out:\n",
    "\t\tpickle.dump(save_object, pickle_out)\n",
    "\n",
    "def load_from_pickle(pickle_file):\n",
    "\twith open(pickle_file, \"rb\") as pickle_in:\n",
    "\t\treturn pickle.load(pickle_in)\n",
    "\n",
    "def save_in_txt(list_of_strings, save_file):\n",
    "\twith open(save_file, \"w\") as writer:\n",
    "\t\tfor line in list_of_strings:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\twriter.write(f\"{line}\\n\")\n",
    "\n",
    "def load_from_txt(txt_file):\n",
    "\twith open(txt_file, \"r\") as reader:\n",
    "\t\tall_lines = list()\n",
    "\t\tfor line in reader:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\tall_lines.append(line)\n",
    "\t\treturn all_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ed704e-8f0c-4750-8c2c-a085911ea7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20b3775-ea62-4292-97b9-c7f2e3d015a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n",
      "                                    author  \\\n",
      "0                      WILLIAM SHAKESPEARE   \n",
      "1  DUCHESS OF NEWCASTLE MARGARET CAVENDISH   \n",
      "2                           THOMAS BASTARD   \n",
      "3                           EDMUND SPENSER   \n",
      "4                        RICHARD BARNFIELD   \n",
      "\n",
      "                                             content  \\\n",
      "0  Let the bird of loudest lay\\r\\nOn the sole Ara...   \n",
      "1  Sir Charles into my chamber coming in,\\r\\nWhen...   \n",
      "2  Our vice runs beyond all that old men saw,\\r\\n...   \n",
      "3  Lo I the man, whose Muse whilome did maske,\\r\\...   \n",
      "4  Long have I longd to see my love againe,\\r\\nSt...   \n",
      "\n",
      "                                 poem name          age                  type  \n",
      "0               The Phoenix and the Turtle  Renaissance  Mythology & Folklore  \n",
      "1                 An Epilogue to the Above  Renaissance  Mythology & Folklore  \n",
      "2                       Book 7, Epigram 42  Renaissance  Mythology & Folklore  \n",
      "3  from The Faerie Queene: Book I, Canto I  Renaissance  Mythology & Folklore  \n",
      "4                                Sonnet 16  Renaissance  Mythology & Folklore  \n"
     ]
    }
   ],
   "source": [
    "data_file = 'with_epoque.csv'\n",
    "data = pd.read_csv(data_file)\n",
    "print(len(data))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "f8073de9-4b6d-4117-8704-60a2266e4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_training(df, char_max_line = 20):\n",
    "    inputs = []\n",
    "    context = []\n",
    "    targets = []\n",
    "    previous = []\n",
    "    for i,rows in df.iterrows():\n",
    "        splitted = rows['content'].split('\\r\\n')\n",
    "        if len(splitted) > 4:\n",
    "            for i,line in enumerate(splitted): \n",
    "                if len(line.strip()) > 0 and len(line.split(' ')) <= char_max_line:\n",
    "                    if i==0:\n",
    "                        previous.append(' ')\n",
    "                    else:\n",
    "                        previous.append(splitted[i-1])\n",
    "                    inputs.append(line)\n",
    "                    targets.append(line)\n",
    "                    context.append(' '.join([str(rows['author'])]))\n",
    "        \n",
    "    return pd.DataFrame(list(zip(inputs, context, targets, previous)),columns =['text', 'context','target', 'previous'])\n",
    "\n",
    "\n",
    "class PoemDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "5a8aecb5-c164-4b77-8849-4c686c2abb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_data_training(data, char_max_line = 30)\n",
    "\n",
    "all_poems = df['text'].tolist()\n",
    "context = df['context'].tolist()\n",
    "previous = df['previous'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "62e57386-ac09-497e-9040-b22699b38e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the vocabulary = 11264\n"
     ]
    }
   ],
   "source": [
    "pad_word = \"<pad>\"\n",
    "bos_word = \"<bos>\"\n",
    "eos_word = \"<eos>\"\n",
    "unk_word = \"<unk>\"\n",
    "sep_word = \"sep\"\n",
    "\n",
    "pad_id = 0\n",
    "bos_id = 1\n",
    "eos_id = 2\n",
    "unk_id = 3\n",
    "sep_id = 4\n",
    "    \n",
    "def normalize_sentence(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word_to_id = {pad_word: pad_id, bos_word: bos_id, eos_word:eos_id, unk_word: unk_id, sep_word: sep_id}\n",
    "        self.word_count = {}\n",
    "        self.id_to_word = {pad_id: pad_word, bos_id: bos_word, eos_id: eos_word, unk_id: unk_word, sep_id: sep_word}\n",
    "        self.num_words = 5\n",
    "    \n",
    "    def get_ids_from_sentence(self, sentence):\n",
    "        sentence = normalize_sentence(sentence)\n",
    "        sent_ids = [bos_id] + [self.word_to_id[word.lower()] if word.lower() in self.word_to_id \\\n",
    "                               else unk_id for word in sentence.split()] + \\\n",
    "                               [eos_id]\n",
    "        return sent_ids\n",
    "    \n",
    "    def tokenized_sentence(self, sentence):\n",
    "        sent_ids = self.get_ids_from_sentence(sentence)\n",
    "        return [self.id_to_word[word_id] for word_id in sent_ids]\n",
    "\n",
    "    def decode_sentence_from_ids(self, sent_ids):\n",
    "        words = list()\n",
    "        for i, word_id in enumerate(sent_ids):\n",
    "            if word_id in [bos_id, eos_id, pad_id]:\n",
    "                continue\n",
    "            else:\n",
    "                words.append(self.id_to_word[word_id])\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def add_words_from_sentence(self, sentence):\n",
    "        sentence = normalize_sentence(sentence)\n",
    "        for word in sentence.split():\n",
    "            if word not in self.word_to_id:\n",
    "                self.word_to_id[word] = self.num_words\n",
    "                self.id_to_word[self.num_words] = word\n",
    "                self.word_count[word] = 1\n",
    "                self.num_words += 1\n",
    "            else:\n",
    "                self.word_count[word] += 1\n",
    "\n",
    "vocab = Vocabulary()\n",
    "for src in df['text']:\n",
    "    vocab.add_words_from_sentence(src.lower())\n",
    "    \n",
    "for cxt in df['context']:\n",
    "    vocab.add_words_from_sentence(cxt.lower())\n",
    "\n",
    "print(f\"Total words in the vocabulary = {vocab.num_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "2cbcf941-49e1-475b-83fe-bf5b3445244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird lay let\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfIdfVectorizer=TfidfVectorizer()\n",
    "tfIdf = tfIdfVectorizer.fit_transform(all_poems)\n",
    "\n",
    "X = tfIdfVectorizer.transform([\"Let the bird of loudest lay\"])\n",
    "names = np.array(tfIdfVectorizer.get_feature_names())\n",
    "ind = np.array(X.indices[X.data.sort()][0][-3:][::-1])\n",
    "res = names[ind]\n",
    "\n",
    "print(' '.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "ca140986-dc0a-446c-8ac4-c40832df65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poem_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, poems, context, previous, vocab, device):\n",
    "\n",
    "        l = []\n",
    "        \n",
    "        for i in range(len(poems)):\n",
    "            X = tfIdfVectorizer.transform([poems[i]])\n",
    "            ind = np.array(X.indices[X.data.sort()][0][-3:][::-1])\n",
    "            key_words = names[ind]\n",
    "            l.append( (context[i] + \" sep \" + ' '.join(key_words), poems[i] ))\n",
    "        \n",
    "        self.poems = l.copy()\n",
    "        self.vocab = vocab\n",
    "        self.device = device\n",
    "\n",
    "        def encode(src, tgt):\n",
    "            src_ids = self.vocab.get_ids_from_sentence(src)\n",
    "            tgt_ids = self.vocab.get_ids_from_sentence(tgt)\n",
    "            return (src_ids, tgt_ids)\n",
    "\n",
    "        # We will pre-tokenize the conversations and save in id lists for later use\n",
    "        self.tokenized_poems = [encode(src, tgt) for src, tgt in self.poems]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.poems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return {\"conv_ids\":self.tokenized_poems[idx], \"conv\":self.poems[idx]}\n",
    "\n",
    "def collate_fn(data):\n",
    "    src_ids = [torch.LongTensor(e[\"conv_ids\"][0]) for e in data]\n",
    "    tgt_ids = [torch.LongTensor(e[\"conv_ids\"][1]) for e in data]\n",
    "    src_str = [e[\"conv\"][0] for e in data]\n",
    "    tgt_str = [e[\"conv\"][1] for e in data]\n",
    "    data = list(zip(src_ids, tgt_ids, src_str, tgt_str))\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    src_ids, tgt_ids, src_str, tgt_str = zip(*data)\n",
    "\n",
    "    src_seqs = nn.utils.rnn.pad_sequence(src_ids, padding_value = pad_id,\n",
    "                                         batch_first = False)\n",
    "    tgt_seqs = nn.utils.rnn.pad_sequence(tgt_ids, padding_value = pad_id, \n",
    "                                         batch_first = False)\n",
    "    \n",
    "    src_padded_length = len(src_seqs[0])\n",
    "    tgt_padded_length = len(tgt_seqs[0])\n",
    "    return {\"conv_ids\":(src_ids, tgt_ids), \"conv\":(src_str, tgt_str), \"conv_tensors\":(src_seqs.to(device), tgt_seqs.to(device))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "4a2568c4-1691-438d-8032-4efce1c000b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Poem_dataset(all_poems, context, previous, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "84b29501-e2a3-4f45-a3e9-8287376d0326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WILLIAM SHAKESPEARE sep bird lay let\n",
      "Let the bird of loudest lay\n",
      "['<bos>', 'william', 'shakespeare', 'sep', 'bird', 'lay', 'let', '<eos>']\n",
      "\n",
      "WILLIAM SHAKESPEARE sep arabian on sole\n",
      "On the sole Arabian tree\n",
      "['<bos>', 'william', 'shakespeare', 'sep', 'arabian', 'on', 'sole', '<eos>']\n",
      "\n",
      "WILLIAM SHAKESPEARE sep and be herald\n",
      "Herald sad and trumpet be,\n",
      "['<bos>', 'william', 'shakespeare', 'sep', 'and', 'be', 'herald', '<eos>']\n",
      "\n",
      "WILLIAM SHAKESPEARE sep chaste obey sound\n",
      "To whose sound chaste wings obey.\n",
      "['<bos>', 'william', 'shakespeare', 'sep', 'chaste', 'obey', 'sound', '<eos>']\n",
      "\n",
      "WILLIAM SHAKESPEARE sep but harbinger shrieking\n",
      "But thou shrieking harbinger,\n",
      "['<bos>', 'william', 'shakespeare', 'sep', 'but', 'harbinger', 'shrieking', '<eos>']\n",
      "\n",
      "Word = world\n",
      "Word ID = 392\n",
      "Word decoded from ID = world\n"
     ]
    }
   ],
   "source": [
    "for src, tgt in dataset.poems[0:5]:\n",
    "    sentence = src\n",
    "    word_tokens = vocab.tokenized_sentence(sentence)\n",
    "    word_ids = vocab.get_ids_from_sentence(sentence)\n",
    "    print(sentence)\n",
    "    print(tgt)\n",
    "    print(word_tokens)\n",
    "    print()\n",
    "\n",
    "word = \"world\"\n",
    "word_id = vocab.word_to_id[word.lower()]\n",
    "print(f\"Word = {word}\")\n",
    "print(f\"Word ID = {word_id}\")\n",
    "print(f\"Word decoded from ID = {vocab.decode_sentence_from_ids([word_id])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "cd5c86bc-fb94-4706-a149-41eab9370f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_GloVe(filename):\n",
    "  embeddings = {}\n",
    "  for line in open(filename).readlines():\n",
    "    fields = line.strip().split(\" \")\n",
    "    word = fields[0]\n",
    "    embeddings[word] = [float(x) for x in fields[1:]]\n",
    "  return embeddings\n",
    "\n",
    "GloVe = read_GloVe(\"glove.840B.300d.conll_filtered.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "ab4b33b3-dd1b-4d0a-8812-38495c9bad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Erato(nn.Module):\n",
    "    def __init__(self, vocab, emb_dim = 300, hidden_dim = 300, num_layers = 2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.num_words = num_words = vocab.num_words\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "   \n",
    "        self.encode_emb = nn.Embedding(self.num_words,self.emb_dim)\n",
    "        \n",
    "        self.init_glove(GloVe, vocab)\n",
    "        \n",
    "        self.encode_gru = nn.GRU(self.emb_dim, self.hidden_dim,\n",
    "                          num_layers=self.num_layers, dropout=dropout,\n",
    "                          bidirectional=True,batch_first=False)\n",
    "        self.encode_l_hidden = nn.Linear(2*self.num_layers,self.num_layers)\n",
    "        self.encode_l_output = nn.Linear(2*self.hidden_dim,self.hidden_dim)\n",
    "\n",
    "        self.dropout_enc = nn.Dropout(dropout)\n",
    "\n",
    "        self.decode_emb = self.encode_emb\n",
    "        \n",
    "        self.decode_gru = nn.GRU(self.emb_dim, self.hidden_dim,\n",
    "                          num_layers=self.num_layers, dropout=dropout,\n",
    "                          bidirectional=False,batch_first=False)\n",
    "        self.d_l = nn.Linear(self.hidden_dim,self.num_words)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=2)\n",
    "        self.loss = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "        self.dropout_dec = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax_att = nn.Softmax(dim=0)\n",
    "        self.attention_matrix = nn.Linear(self.hidden_dim,self.hidden_dim)\n",
    "        self.attention_decode_cat = nn.Linear(2*self.hidden_dim,self.num_words)\n",
    "    \n",
    "    def init_glove(self, GloVe, vocab):\n",
    "        weights_emb = self.encode_emb.weight.data.clone()\n",
    "        \n",
    "        for i, word in enumerate(vocab.word_to_id):\n",
    "            if word in GloVe:\n",
    "                weights_emb[vocab.word_to_id[word],:] = torch.tensor(GloVe[word])\n",
    "          \n",
    "        self.encode_emb = nn.Embedding.from_pretrained(weights_emb.clone(),freeze = False)\n",
    "    \n",
    "    def encode(self, source):\n",
    "        source_lengths = torch.sum(source != pad_id, axis=0).cpu()\n",
    "\n",
    "        emb = self.dropout_enc(self.encode_emb(source))\n",
    "        emb = nn.utils.rnn.pack_padded_sequence(emb, source_lengths,\n",
    "                                                enforce_sorted = False)\n",
    "        encoder_output, encoder_hidden = self.encode_gru(emb)\n",
    "        encoder_output,_ = nn.utils.rnn.pad_packed_sequence(encoder_output,\n",
    "                                                   padding_value=pad_id)\n",
    "  \n",
    "        encoder_output = self.encode_l_output(encoder_output)\n",
    "        \n",
    "        encoder_hidden = self.encode_l_hidden(encoder_hidden.permute(2,1,0))\n",
    "        encoder_hidden = encoder_hidden.permute(2,1,0).contiguous()\n",
    "        # Compute the encoder mask\n",
    "        encoder_mask = (source == pad_id)\n",
    "\n",
    "        return encoder_output, encoder_mask.type(torch.bool), encoder_hidden\n",
    "\n",
    "    def decode(self, decoder_input, last_hidden, encoder_output, encoder_mask):\n",
    "\n",
    "        emb = self.dropout_dec(self.decode_emb(decoder_input))\n",
    "        decoder_output, decoder_hidden = self.decode_gru(emb,last_hidden)\n",
    "        b = decoder_output.squeeze(0)\n",
    "\n",
    "        # I use the General method (Luong2015) for attention\n",
    "        encoder_output = encoder_output.masked_fill(encoder_mask.unsqueeze(2),0)\n",
    "        att = torch.matmul(self.attention_matrix(decoder_output.permute(1,0,2)),\n",
    "                           encoder_output.permute(1,2,0))\n",
    "        att = att.squeeze(1).permute(1,0)\n",
    "        \n",
    "        att = att.masked_fill(encoder_mask, float(\"-inf\"))\n",
    "        att = self.softmax_att(att)\n",
    "        c = att.unsqueeze(2) * encoder_output\n",
    "        c = torch.sum(c,0)\n",
    "        logits = self.attention_decode_cat(torch.cat((b,c),1))\n",
    "        return (logits, decoder_hidden, att)\n",
    "\n",
    "    def compute_loss(self, source, target):\n",
    "\n",
    "        max_source_sequence_length = target.shape[0]\n",
    "        local_batch_size = target.shape[1]\n",
    "        encoder_output, encoder_mask, h = self.encode(source)\n",
    "        input_decode = target[0,:].unsqueeze(0)\n",
    "        loss = 0\n",
    "        for t in range(1,max_source_sequence_length):\n",
    "            out,h,_ = self.decode(input_decode, h, encoder_output, encoder_mask)\n",
    "            input_decode = target[t,:].unsqueeze(0)\n",
    "            loss += self.loss(out, input_decode.squeeze())\n",
    "        return loss / (max_source_sequence_length-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "0c01483e-0a77-43d9-b785-90301515be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, num_epochs, model_file, learning_rate=0.0001):\n",
    "\n",
    "    decoder_learning_ratio = 5.0\n",
    "    encoder_parameter_names = ['encode_emb', 'encode_gru', 'l1', 'l2']\n",
    "                           \n",
    "    encoder_named_params = list(filter(lambda kv: any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
    "    decoder_named_params = list(filter(lambda kv: not any(key in kv[0] for key in encoder_parameter_names), model.named_parameters()))\n",
    "    encoder_params = [e[1] for e in encoder_named_params]\n",
    "    decoder_params = [e[1] for e in decoder_named_params]\n",
    "    optimizer = torch.optim.AdamW([{'params': encoder_params},\n",
    "                {'params': decoder_params, 'lr': learning_rate * decoder_learning_ratio}], lr=learning_rate)\n",
    "    \n",
    "    clip = 50.0\n",
    "    for epoch in tqdm.notebook.trange(num_epochs, desc=\"training\", unit=\"epoch\"):\n",
    "        with tqdm.notebook.tqdm(\n",
    "                data_loader,\n",
    "                desc=\"epoch {}\".format(epoch + 1),\n",
    "                unit=\"batch\",\n",
    "                total=len(data_loader)) as batch_iterator:\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for i, batch_data in enumerate(batch_iterator, start=1):\n",
    "                source, target = batch_data[\"conv_tensors\"]\n",
    "                optimizer.zero_grad()\n",
    "                loss = model.compute_loss(source, target)\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                _ = nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item())\n",
    "       \n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56066f16-c0f0-4c45-8ac2-53d0f918695e",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "55260cf1-8ca4-4de1-af19-31d0b89de0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Erato_model = Erato(vocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "c3250c3a-5cd5-45df-99ee-bfa97cdc34a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2478d316f5554eb59978f5825c086fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/5 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3f55902bfa402d82be4531fa5f8f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd39f2c0c61d46eb80a10f8398b81fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0bed9cbfab4ec4a8940ca1f9ce09bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea65e6c87c34fc8ac0e69b0c8ded9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a649cfe0bdf4d50a632fed02986c4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5:   0%|          | 0/211 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                               shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "train(Erato_model, data_loader, num_epochs, \"baseline_model.pt\",learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "292c5c6a-1094-4705-bde6-9b2e79b88e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = \"./saved_Erato\"\n",
    "torch.save(Erato_model, Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "2a464ba5-37c6-4db9-b876-41fbfaecde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Erato_model = torch.load(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "eb7d37ef-ac4f-4791-9ad5-3b350f514517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_greedy(model, sentence, max_length=100):\n",
    "    \"\"\"Make predictions for the given input using greedy inference.\n",
    "    \n",
    "    Args:\n",
    "        model: A sequence-to-sequence model.\n",
    "        sentence: A input string.\n",
    "        max_length: The maximum length at which to truncate outputs in order to\n",
    "            avoid non-terminating inference.\n",
    "    \n",
    "    Returns:\n",
    "        Model's predicted greedy response for the input, represented as string.\n",
    "    \"\"\"\n",
    "\n",
    "    # You should make only one call to model.encode() at the start of the function, \n",
    "    # and make only one call to model.decode() per inference step.\n",
    "    model.eval()    \n",
    "    src_id = torch.tensor(vocab.get_ids_from_sentence(sentence))[:,None].to(device)\n",
    "    encoder_output, encoder_mask, last_hidden = model.encode(src_id) \n",
    "    input = src_id[0,:]\n",
    "    out = [bos_id]\n",
    "    for t in range(max_length):\n",
    "        input = input[None,:]\n",
    "        out_decoder, last_hidden, _ = model.decode(input, last_hidden, encoder_output, encoder_mask)\n",
    "        input = out_decoder.argmax(dim=-1)\n",
    "        word = input.item()\n",
    "        out.append(word)\n",
    "        if word == eos_id:\n",
    "            break\n",
    "    \n",
    "    decoded = vocab.decode_sentence_from_ids(out)\n",
    "    return decoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "c8a35318-02d0-46b1-9be2-e57f82b556e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam(model, sentence, k=5, max_length=100, hidden = None):\n",
    "\n",
    "    alpha = 0.3\n",
    "    model.eval()\n",
    "    \n",
    "    sentence_ids = torch.tensor(vocab.get_ids_from_sentence(sentence)).cuda()\n",
    "    sentence_ids = sentence_ids.unsqueeze(1)\n",
    "    encoder_output, encoder_mask, h = model.encode(sentence_ids)\n",
    "\n",
    "    out_start = sentence_ids[0]\n",
    "    beam = [out_start for i in range(k)]\n",
    "    beam_scores = [1 for i in range(k)]\n",
    "    \n",
    "    if hidden:\n",
    "        h = hidden\n",
    "    hiddens = [h for i in range(k)]\n",
    "    \n",
    "    generations = []\n",
    "    generations_scores = []\n",
    "    curr_l = 0\n",
    "    eos_tensor = torch.Tensor([eos_id]).int().cuda()\n",
    "    while beam:\n",
    "        logits = torch.Tensor().cuda()\n",
    "        inds = torch.Tensor().int().cuda()\n",
    "        curr_k = len(beam)\n",
    "        if curr_l==max_length:\n",
    "            for i in range(curr_k):\n",
    "                  generations += [torch.cat((beam[i],eos_tensor),0)]\n",
    "                  generations_scores += [new_beam_scores[i]]\n",
    "            break\n",
    "        else:\n",
    "            for i in range(curr_k):\n",
    "                out, hiddens[i], _ = model.decode(beam[i][-1].view(1,1), hiddens[i], encoder_output,\n",
    "                                     encoder_mask)\n",
    "                logit,ind = torch.topk(out.squeeze(), curr_k, dim=0)\n",
    "                logits = torch.cat((logits,logit),0)\n",
    "                inds = torch.cat((inds,ind),0)\n",
    "            new_beam = []\n",
    "            new_beam_scores = []\n",
    "            new_hiddens = []\n",
    "            if curr_l==0:\n",
    "                for i in range(curr_k):\n",
    "                    max_ind = torch.argmax(nn.functional.log_softmax(logit,dim=0))\n",
    "                    new_beam_scores += [float(logit[max_ind])]\n",
    "                    logit[max_ind] = -1e9\n",
    "                    new_beam += [torch.cat((beam[0],ind[max_ind].unsqueeze(0)),0)]\n",
    "                    new_hiddens += [hiddens[0]]\n",
    "            else:\n",
    "                top_logits,top_inds_logit = torch.topk(torch.repeat_interleave(torch.Tensor(beam_scores).cuda(),\n",
    "                                                                               curr_k)\\\n",
    "                                                       +nn.functional.log_softmax(logits,dim=0),\n",
    "                                                       curr_k, dim=0)\n",
    "                for i in range(curr_k):\n",
    "                    if inds[top_inds_logit[i]]==eos_id:\n",
    "                        generations += [torch.cat((beam[top_inds_logit[i]//curr_k],inds[top_inds_logit[i]].unsqueeze(0)),0)]\n",
    "                        generations_scores+=[float(logits[top_inds_logit[i]])/(generations[-1].shape[0]**alpha)]\n",
    "                    else:\n",
    "                        new_beam += [torch.cat((beam[top_inds_logit[i]//curr_k],inds[top_inds_logit[i]].unsqueeze(0)),0)]\n",
    "                        new_hiddens += [hiddens[top_inds_logit[i]//curr_k]]\n",
    "                        new_beam_scores += [float(logits[top_inds_logit[i]])]\n",
    "            beam = new_beam\n",
    "            beam_scores = new_beam_scores\n",
    "            hiddens = new_hiddens\n",
    "        curr_l +=1\n",
    "    generations = [g for _, g in sorted(zip(generations_scores, generations))]\n",
    "    generations.reverse()\n",
    "    sorted_scores = sorted(generations_scores)\n",
    "    sorted_scores.reverse()\n",
    "    return [vocab.decode_sentence_from_ids(s.tolist()) for s in generations], sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "7cb6ee6f-1151-414c-80a5-bcfc26ed611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam2(model, sentence, k=5, max_length=100):\n",
    "    \"\"\"Make predictions for the given inputs using beam search.\n",
    "    \n",
    "    Args:\n",
    "        model: A sequence-to-sequence model.\n",
    "        sentence: An input sentence, represented as string.\n",
    "        k: The size of the beam.\n",
    "        max_length: The maximum length at which to truncate outputs in order to\n",
    "            avoid non-terminating inference.\n",
    "    \n",
    "    Returns:\n",
    "        A list of k beam predictions. Each element in the list should be a string\n",
    "        corresponding to one of the top k predictions for the corresponding input,\n",
    "        sorted in descending order by its final score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementation tip: once an eos_token has been generated for any beam, \n",
    "    # remove its subsequent predictions from that beam by adding a small negative \n",
    "    # number like -1e9 to the appropriate logits. This will ensure that the \n",
    "    # candidates are removed from the beam, as its probability will be very close\n",
    "    # to 0. Using this method, uou will be able to reuse the beam of an already \n",
    "    # finished candidate\n",
    "\n",
    "    # Implementation tip: while you are encouraged to keep your tensor dimensions\n",
    "    # constant for simplicity (aside from the sequence length), some special care\n",
    "    # will need to be taken on the first iteration to ensure that your beam\n",
    "    # doesn't fill up with k identical copies of the same candidate.\n",
    "    \n",
    "    # You are welcome to tweak alpha\n",
    "    alpha = 0.7\n",
    "    model.eval()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    log_P_T = torch.log(torch.tensor(list(vocab.word_count.values()))/len(vocab.word_count.values())).to(device)\n",
    "    \n",
    "    beams = torch.ones((max_length,k*k)) * bos_id\n",
    "    probs = torch.ones((max_length,k*k))\n",
    "    top_beams = (torch.ones(k,device = device, dtype = torch.int) * bos_id)\n",
    "    top_probs = (torch.zeros(k,device = device, dtype = torch.int))\n",
    "    src_id = torch.tensor(vocab.get_ids_from_sentence(sentence))[:,None].to(device)\n",
    "    encoder_output, encoder_mask, last_hidden = model.encode(src_id)\n",
    "    hidden_list = [last_hidden for i in range(k)]\n",
    "    current_beams = [[bos_id] for i in range(k)]\n",
    "    input = src_id[None,0,:]\n",
    "    generations = []\n",
    "    generations_scores = []\n",
    "    \n",
    "    for t in range(max_length):\n",
    "        start_hidden = last_hidden\n",
    "        for i in range(k):\n",
    "            last_hidden = hidden_list[i]\n",
    "            input = top_beams[None,None,i]\n",
    "            out_decoder, last_hidden, _ = model.decode(input, last_hidden, encoder_output, encoder_mask)\n",
    "            out_decoder = nn.functional.log_softmax(out_decoder, dim = 2)\n",
    "            sorted, indices  = torch.sort(out_decoder, dim=- 1, descending=True)\n",
    "            beams[t+1,i*k:(i+1)*k] = indices[0,0,0:k]\n",
    "            probs[t+1,i*k:(i+1)*k] = top_probs[i] + sorted[0,0,0:k] \n",
    "            hidden_list[i] = last_hidden\n",
    "        \n",
    "        if t == 0:\n",
    "            values_p = probs[t+1,:].unique()\n",
    "            beams_p = beams[t+1,:].unique()\n",
    "            sorts, inds = torch.sort(values_p, dim=- 1, descending=True)\n",
    "            top_beams = beams_p[inds].int().to(device)\n",
    "            \n",
    "            for j,l in enumerate(current_beams):\n",
    "                l.append(top_beams[j].item())\n",
    "            \n",
    "        else:\n",
    "            sorted_p, indices_p = torch.sort(probs[t+1,:], dim=- 1, descending=True)\n",
    "            top_probs = sorted_p[0:k]\n",
    "            top_beams = beams[t+1,indices_p[0:k]].int().to(device)\n",
    "            ancestor = torch.div(indices_p[0:k], k, rounding_mode='floor')\n",
    "            prev_beams = current_beams\n",
    "            current_beams = []\n",
    "            prev_hidden_list = hidden_list.copy()\n",
    "            hidden_list = []\n",
    "            for j, a in enumerate(ancestor):\n",
    "                current_beams.append(prev_beams[a]+[top_beams[j].item()])\n",
    "                hidden_list.append(prev_hidden_list[a])\n",
    "#         print(list(map(vocab.decode_sentence_from_ids,current_beams)))\n",
    "        \n",
    "        for i,l in enumerate(current_beams):\n",
    "            if l[-1] == eos_id:\n",
    "                generations.append(vocab.decode_sentence_from_ids(l))\n",
    "                generations_scores.append(top_probs[i].item())\n",
    "                if len(generations) == k:\n",
    "                    lens_sent = [len(s) for s in generations]\n",
    "                    scores = [ s/(l**alpha) for s,l in zip(generations_scores,lens_sent)]\n",
    "                    sorted_gen = np.array(generations)[np.argsort(scores)[::-1]]\n",
    "                    return sorted_gen\n",
    "                top_probs[i] = float(\"-inf\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "a4b8d71f-84c9-4cab-acf9-17b9d1b3b57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought i thought this thought thought i thought this thought\n",
      "\n",
      "['when i thought this thought i thought this thought should thought', 'when i thought i thought this thought was thought', 'yet i thought i thought this thought was thought', 'when i thought this thought i thought this thought', 'when i thought this thought i thought this thought should i']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"WILLIAM SHAKESPEARE sep i thought i thought i thought i thought ,\"\n",
    "print(predict_greedy(Erato_model, sentence, max_length=100))\n",
    "print()\n",
    "b, s = predict_beam(Erato_model, sentence, k=5, max_length=100)\n",
    "\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "5ca23a25-8c81-4d9c-9dd8-228d4b8c9eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18048/1608612418.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"WILLIAM SHAKESPEARE sep i thought i thought i thought i thought ,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredict_beam2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErato_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18048/2776607501.py\u001b[0m in \u001b[0;36mpredict_beam2\u001b[1;34m(model, sentence, k, max_length)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop_beams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mout_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mout_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[0msorted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mbeams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1766\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"log_softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "sentence = \"WILLIAM SHAKESPEARE sep i thought i thought i thought i thought ,\"\n",
    "predict_beam2(Erato_model, sentence, k=5, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "087b7a81-5122-4228-bda7-41a7167fbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_peom(model, author, key_words, method = \"greedy\", k_beam = 10, nb_line = 5):\n",
    "    out = []\n",
    "    inp_sentence = author + \" sep \" +  ' '.join(key_words)\n",
    "    print(inp_sentence)\n",
    "    print()\n",
    "    for nb in range(nb_line):\n",
    "        if method == \"greedy\":\n",
    "            sent_out = predict_greedy(model, inp_sentence, max_length=100)\n",
    "            out.append(sent_out)\n",
    "            inp_sentence = author + \" sep \" + sent_out  \n",
    "            \n",
    "        else:\n",
    "            sent_out_beam, scores = predict_beam(model, inp_sentence, k=k_beam, max_length=100)\n",
    "            sent_out = sent_out_beam[0]\n",
    "            scores = np.array(scores)/sum(scores)\n",
    "            out_sent = np.random.choice(sent_out_beam, p = scores)\n",
    "            out.append(out_sent)\n",
    "            rand_words = np.random.choice(out_sent.split(),2)\n",
    "            inp_sentence = author + \" sep \" + ' '.join(key_words) + ' '.join(rand_words)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "f64191b9-5c73-4b17-9ba4-fe39d145a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THOMAS BASTARD sep sea\n",
      "\n",
      "a deep light upon the old sea,\n",
      "off to sing a deep cloud,\n",
      "while thou sing st the best s delight,\n",
      "powdered thou upon their beauties feet .,\n",
      "when i must fortune out upon the wall .,\n",
      "rewards upon our cruel plaine,\n",
      "while i am slain of cruel cheer,\n",
      "blest a honour in a field of labor .,\n",
      "a store of a dreadful priest s light,\n",
      "vouchsafe up a cruel light upon\n"
     ]
    }
   ],
   "source": [
    "key_words = ['sea']\n",
    "author = \"THOMAS BASTARD\"\n",
    "method = \"beam\"\n",
    "poem = generate_peom(Erato_model, author, key_words, method = method, k_beam = 50, nb_line = 10)\n",
    "\n",
    "\n",
    "print(',\\n'.join(poem))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
